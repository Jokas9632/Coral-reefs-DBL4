{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b7f80f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0d9328ffba45e1acb24e451695c883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1517 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15c2f34aa8341a48291ace7d1f6e852",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/166 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61531fcc904046e5892bfad01da6979c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/392 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Login using e.g. `huggingface-cli login` to access this dataset\n",
    "ds = load_dataset(\"EPFL-ECEO/coralscapes\")\n",
    "#train_dataset = load_dataset(\"EPFL-ECEO/coralscapes\", split=\"train\")\n",
    "#valid_dataset = load_dataset(\"EPFL-ECEO/coralscapes\", split=\"validation\")\n",
    "#test_dataset  = load_dataset(\"EPFL-ECEO/coralscapes\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "686d3e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: recolor+pack: 100%|██████████| 1517/1517 [03:38<00:00,  6.95it/s]\n",
      "validation: recolor+pack: 100%|██████████| 166/166 [00:19<00:00,  8.30it/s]\n",
      "test: recolor+pack: 100%|██████████| 392/392 [00:47<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done. Parquet parts in: coralscapes_export\\parquet\n",
      "Preview PNGs in: coralscapes_export\\samples\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# ----- class id sets -----\n",
    "HEALTHY_IDS = {6, 17, 22, 25, 28, 31, 34, 36, 27}\n",
    "UNHEALTHY_IDS = {3, 4, 16, 23, 19, 20, 32, 33, 37}\n",
    "RED   = np.array([255, 0,   0], dtype=np.uint8)\n",
    "BLUE  = np.array([0,   0, 255], dtype=np.uint8)\n",
    "BLACK = np.array([0,   0,   0], dtype=np.uint8)\n",
    "\n",
    "# ----- helpers -----\n",
    "def pil_to_png_bytes(img: Image.Image) -> bytes:\n",
    "    buf = BytesIO(); img.save(buf, format=\"PNG\"); return buf.getvalue()\n",
    "\n",
    "def label_pil_to_id_array(lbl: Image.Image) -> np.ndarray:\n",
    "    if lbl.mode in (\"P\", \"L\", \"I\"):\n",
    "        return np.array(lbl).astype(np.int32)\n",
    "    raise ValueError(f\"Label mode {lbl.mode} is not an ID mask.\")\n",
    "\n",
    "def ids_to_health_rgb(id_mask: np.ndarray) -> Image.Image:\n",
    "    out = np.zeros_like(id_mask, dtype=np.uint8)\n",
    "    out[np.isin(id_mask, list(HEALTHY_IDS))] = 1\n",
    "    out[np.isin(id_mask, list(UNHEALTHY_IDS))] = 2\n",
    "    h, w = out.shape\n",
    "    rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    rgb[out == 1] = RED\n",
    "    rgb[out == 2] = BLUE\n",
    "    return Image.fromarray(rgb, mode=\"RGB\")\n",
    "\n",
    "def table_size_bytes(table: pa.Table, compression: str = \"zstd\") -> int:\n",
    "    sink = pa.BufferOutputStream()\n",
    "    pq.write_table(table, sink, compression=compression)\n",
    "    return sink.getvalue().size\n",
    "\n",
    "def write_parquet_chunk(rows, out_path: Path, compression: str = \"zstd\"):\n",
    "    table = pa.table(rows)\n",
    "    pq.write_table(table, out_path.as_posix(), compression=compression)\n",
    "\n",
    "def export_split_to_parquet(\n",
    "    ds_split,\n",
    "    split_name: str,\n",
    "    out_parquet_dir: Path,\n",
    "    include_images: bool,\n",
    "    target_mb: float = 19.0,\n",
    "    compression: str = \"zstd\",\n",
    "    preview_dir: Path | None = None,\n",
    "    preview_n: int = 5,\n",
    "):\n",
    "    out_parquet_dir.mkdir(parents=True, exist_ok=True)\n",
    "    if preview_dir: preview_dir.mkdir(parents=True, exist_ok=True)\n",
    "    TARGET = int(target_mb * 1024 * 1024)\n",
    "\n",
    "    cur = {\"split\": [], \"index\": [], \"label_health_rgb_png\": []}\n",
    "    if include_images: cur[\"image_png\"] = []\n",
    "    part_idx, n = 1, len(ds_split)\n",
    "\n",
    "    for i in tqdm(range(n), desc=f\"{split_name}: recolor+pack\"):\n",
    "        rec = ds_split[i]\n",
    "        img: Image.Image  = rec[\"image\"]\n",
    "        lbl: Image.Image  = rec[\"label\"]\n",
    "\n",
    "        ids = label_pil_to_id_array(lbl)\n",
    "        health_rgb = ids_to_health_rgb(ids)\n",
    "\n",
    "        label_png = pil_to_png_bytes(health_rgb)\n",
    "        if include_images: image_png = pil_to_png_bytes(img)\n",
    "\n",
    "        cur[\"split\"].append(split_name)\n",
    "        cur[\"index\"].append(i)\n",
    "        cur[\"label_health_rgb_png\"].append(label_png)\n",
    "        if include_images: cur[\"image_png\"].append(image_png)\n",
    "\n",
    "        est = table_size_bytes(pa.table(cur), compression=compression)\n",
    "        if est > TARGET:\n",
    "            for k in list(cur.keys()): cur[k].pop()\n",
    "            if len(cur[\"index\"]) > 0:\n",
    "                out_path = out_parquet_dir / f\"{split_name}_part{part_idx:03d}.parquet\"\n",
    "                write_parquet_chunk(cur, out_path, compression=compression)\n",
    "                part_idx += 1\n",
    "                cur = {k: [] for k in cur.keys()}\n",
    "            cur[\"split\"].append(split_name)\n",
    "            cur[\"index\"].append(i)\n",
    "            cur[\"label_health_rgb_png\"].append(label_png)\n",
    "            if include_images: cur[\"image_png\"].append(image_png)\n",
    "            if table_size_bytes(pa.table(cur), compression=compression) > TARGET:\n",
    "                out_path = out_parquet_dir / f\"{split_name}_part{part_idx:03d}.parquet\"\n",
    "                write_parquet_chunk(cur, out_path, compression=compression)\n",
    "                part_idx += 1\n",
    "                cur = {k: [] for k in cur.keys()}\n",
    "\n",
    "        if preview_dir and i < preview_n:\n",
    "            health_rgb.save(preview_dir / f\"{split_name}_{i:05d}_label_health_rgb.png\")\n",
    "\n",
    "    if len(cur[\"index\"]) > 0:\n",
    "        out_path = out_parquet_dir / f\"{split_name}_part{part_idx:03d}.parquet\"\n",
    "        write_parquet_chunk(cur, out_path, compression=compression)\n",
    "\n",
    "def run_pipeline(outdir=\"coralscapes_export\", include_images=False, target_mb=19.0):\n",
    "    out_root = Path(outdir)\n",
    "    parquet_dir = out_root / \"parquet\"\n",
    "    samples_dir = out_root / \"samples\"\n",
    "    parquet_dir.mkdir(parents=True, exist_ok=True)\n",
    "    samples_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ds = load_dataset(\"EPFL-ECEO/coralscapes\")\n",
    "    for split in (\"train\", \"validation\", \"test\"):\n",
    "        if split not in ds: continue\n",
    "        export_split_to_parquet(\n",
    "            ds_split=ds[split],\n",
    "            split_name=split,\n",
    "            out_parquet_dir=parquet_dir / split,\n",
    "            include_images=include_images,\n",
    "            target_mb=target_mb,\n",
    "            compression=\"zstd\",\n",
    "            preview_dir=samples_dir / split,\n",
    "            preview_n=5,\n",
    "        )\n",
    "    print(f\"Done. Parquet parts in: {parquet_dir}\")\n",
    "    print(f\"Preview PNGs in: {samples_dir}\")\n",
    "\n",
    "# <<< RUN IT HERE >>>\n",
    "run_pipeline(outdir=\"coralscapes_export\", include_images=False, target_mb=19.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871f181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
