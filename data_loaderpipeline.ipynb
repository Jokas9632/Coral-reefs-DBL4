{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4c6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path exists: G:\\.shortcut-targets-by-id\\1v4g4qOrbisBvrpqOxLrYn96nd_gPG_Ge\\dc4data\n",
      "Path exists: G:\\.shortcut-targets-by-id\\1mx2OJcVKp1mRbTbjezqWucDXpbGrd_OA\\benthic_datasets\n",
      "Path exists: G:\\.shortcut-targets-by-id\\1jGkNA1n0znoxKnQBHTJZuPgvkiu_OBM8\\coral_bleaching\n",
      "Path exists: G:\\.shortcut-targets-by-id\\1v4g4qOrbisBvrpqOxLrYn96nd_gPG_Ge\\dc4data\\coralscapes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import win32com.client\n",
    "def resolve_shortcut(path):\n",
    "    shell = win32com.client.Dispatch(\"WScript.Shell\")\n",
    "    shortcut = shell.CreateShortCut(path)\n",
    "    return shortcut.Targetpath\n",
    "\n",
    "data_path = resolve_shortcut(r\"G:\\\\My Drive\\\\dc4data.lnk\")\n",
    "benthic_path = resolve_shortcut(data_path+r\"\\\\benthic_datasets.lnk\")\n",
    "coralbleaching_path = resolve_shortcut(data_path+r\"\\\\coral_bleaching.lnk\")\n",
    "if not os.path.exists(r\"G:\\.shortcut-targets-by-id\\1v4g4qOrbisBvrpqOxLrYn96nd_gPG_Ge\\dc4data\\coralscapes\"):\n",
    "     coralscapes_path = resolve_shortcut(data_path+r\"\\\\coralscapes.lnk\")\n",
    "else:\n",
    "        coralscapes_path = r\"G:\\.shortcut-targets-by-id\\1v4g4qOrbisBvrpqOxLrYn96nd_gPG_Ge\\dc4data\\coralscapes\"\n",
    "for p in [data_path, benthic_path, coralbleaching_path, coralscapes_path]:\n",
    "    if os.path.exists(p):\n",
    "        print(f\"Path exists: {p}\")\n",
    "    if not os.path.exists(p):\n",
    "        raise FileNotFoundError(f\"Path does not exist: {p}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4494b98d",
   "metadata": {},
   "source": [
    "## Benthic Datset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6203fed2",
   "metadata": {},
   "source": [
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09b408d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import pyarrow.parquet as pq\n",
    "from io import BytesIO\n",
    "from pathlib import Path\n",
    "from typing import Optional, Callable, Union, Sequence, List\n",
    "\n",
    "benthic_paths = [r\"G:\\.shortcut-targets-by-id\\1mx2OJcVKp1mRbTbjezqWucDXpbGrd_OA\\benthic_datasets\\mask_labels\\reef_support\\SEAFLOWER_BOLIVAR\",\n",
    "r\"G:\\.shortcut-targets-by-id\\1mx2OJcVKp1mRbTbjezqWucDXpbGrd_OA\\benthic_datasets\\mask_labels\\reef_support\\SEAFLOWER_COURTOWN\",\n",
    "r\"G:\\.shortcut-targets-by-id\\1mx2OJcVKp1mRbTbjezqWucDXpbGrd_OA\\benthic_datasets\\mask_labels\\reef_support\\SEAVIEW_PAC_USA\",\n",
    "r\"G:\\.shortcut-targets-by-id\\1mx2OJcVKp1mRbTbjezqWucDXpbGrd_OA\\benthic_datasets\\mask_labels\\reef_support\\SEAVIEW_IDN_PHL\",\n",
    "r\"G:\\.shortcut-targets-by-id\\1mx2OJcVKp1mRbTbjezqWucDXpbGrd_OA\\benthic_datasets\\mask_labels\\reef_support\\SEAVIEW_PAC_AUS\",\n",
    "r\"G:\\.shortcut-targets-by-id\\1mx2OJcVKp1mRbTbjezqWucDXpbGrd_OA\\benthic_datasets\\mask_labels\\reef_support\\TETES_PROVIDENCIA\",\n",
    "r\"G:\\.shortcut-targets-by-id\\1mx2OJcVKp1mRbTbjezqWucDXpbGrd_OA\\benthic_datasets\\mask_labels\\reef_support\\SEAVIEW_ATL\",\n",
    "r\"G:\\.shortcut-targets-by-id\\1mx2OJcVKp1mRbTbjezqWucDXpbGrd_OA\\benthic_datasets\\mask_labels\\reef_support\\UNAL_BLEACHING_TAYRONA\",]\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        # keep only typical image files; sorted for reproducibility\n",
    "        exts = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "        self.images = sorted([f for f in os.listdir(img_dir) if f.lower().endswith(exts)])\n",
    "\n",
    "        if not self.images:\n",
    "            raise FileNotFoundError(f\"No images found in {img_dir}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        img_path = os.path.join(self.img_dir, img_name)\n",
    "\n",
    "        # Map \"name.ext\" -> \"name_mask.png\" (as you requested)\n",
    "        stem = Path(img_name).stem\n",
    "        mask_name = f\"{stem}_mask.png\"\n",
    "        mask_path = os.path.join(self.mask_dir, mask_name)\n",
    "\n",
    "        if not os.path.exists(mask_path):\n",
    "            raise FileNotFoundError(\n",
    "                f\"Mask not found for {img_name}. Expected: {mask_path} \"\n",
    "                \"(pattern '<image_stem>_mask.png').\"\n",
    "            )\n",
    "\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask\n",
    "\n",
    "\n",
    "def get_mask(benthic_folder):\n",
    "    mask_path = os.path.join(benthic_folder, 'masks_stitched')\n",
    "    return mask_path\n",
    "\n",
    "def get_image(benthic_folder):\n",
    "    image_path = os.path.join(benthic_folder, 'images')\n",
    "    return image_path\n",
    "\n",
    "\n",
    "#DATASETS\n",
    "SEAFLOWER_BOLIVAR = SegmentationDataset(get_image(benthic_paths[0]), get_mask(benthic_paths[0]))\n",
    "SEAFLOWER_COURTOWN = SegmentationDataset(get_image(benthic_paths[1]), get_mask(benthic_paths[1]))\n",
    "SEAVIEW_PAC_USA = SegmentationDataset(get_image(benthic_paths[2]), get_mask(benthic_paths[2]))\n",
    "SEAVIEW_IDN_PHL = SegmentationDataset(get_image(benthic_paths[3]), get_mask(benthic_paths[3]))\n",
    "SEAVIEW_PAC_AUS = SegmentationDataset(get_image(benthic_paths[4]), get_mask(benthic_paths[4]))\n",
    "TETES_PROVIDENCIA = SegmentationDataset(get_image(benthic_paths[5]), get_mask(benthic_paths[5]))\n",
    "SEAVIEW_ATL = SegmentationDataset(get_image(benthic_paths[6]), get_mask(benthic_paths[6]))\n",
    "UNAL_BLEACHING_TAYRONA = SegmentationDataset(get_image(benthic_paths[7]), get_mask(benthic_paths[7]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427dad19",
   "metadata": {},
   "source": [
    "## Coral Scapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c8eeb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- helper: load masks from parquet parts by dataset index ---\n",
    "class _ParquetMasksByIndex:\n",
    "    def __init__(self, parquet_dir_or_paths: Union[str, Path, Sequence[Union[str, Path]]],\n",
    "                 column_png: str = \"label_health_rgb_png\"):\n",
    "        # normalize to list of parquet files\n",
    "        if isinstance(parquet_dir_or_paths, (str, Path)):\n",
    "            p = Path(parquet_dir_or_paths)\n",
    "            if p.is_dir():\n",
    "                paths = sorted(p.glob(\"*.parquet\"))\n",
    "                if not paths:\n",
    "                    raise FileNotFoundError(f\"No parquet files in directory: {p}\")\n",
    "            else:\n",
    "                if not p.exists():\n",
    "                    raise FileNotFoundError(f\"Parquet file not found: {p}\")\n",
    "                paths = [p]\n",
    "        else:\n",
    "            paths = [Path(x) for x in parquet_dir_or_paths]\n",
    "            for p in paths:\n",
    "                if not p.exists():\n",
    "                    raise FileNotFoundError(f\"Parquet file not found: {p}\")\n",
    "\n",
    "        self._tables = [pq.read_table(p) for p in paths]\n",
    "        for t in self._tables:\n",
    "            if \"index\" not in t.column_names or column_png not in t.column_names:\n",
    "                raise ValueError(f\"Parquet must have 'index' and '{column_png}'. Got: {t.column_names}\")\n",
    "        self._colname = column_png\n",
    "\n",
    "        # build index -> (table_id, row_id)\n",
    "        self._map = {}\n",
    "        for tid, t in enumerate(self._tables):\n",
    "            idxs = t[\"index\"].to_pylist()\n",
    "            for rid, ds_idx in enumerate(idxs):\n",
    "                self._map[int(ds_idx)] = (tid, rid)\n",
    "\n",
    "    def get_mask_pil(self, ds_index: int) -> Image.Image:\n",
    "        tid, rid = self._map[ds_index]\n",
    "        cell = self._tables[tid][self._colname][rid].as_py()\n",
    "        if isinstance(cell, memoryview):\n",
    "            cell = cell.tobytes()\n",
    "        elif isinstance(cell, bytearray):\n",
    "            cell = bytes(cell)\n",
    "        return Image.open(BytesIO(cell)).convert(\"RGB\")\n",
    "    \n",
    "class CoralScapesImagesMasks(Dataset):\n",
    "    \"\"\"\n",
    "    Images:\n",
    "      - Either from HF split (set split=\"train\"/\"validation\"/\"test\")\n",
    "      - Or from local Arrow shards (set arrow_paths=[...])\n",
    "    Masks:\n",
    "      - From your Parquet export (dir or list), matched by dataset index.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 parquet_dir_or_paths: Union[str, Path, Sequence[Union[str, Path]]],\n",
    "                 split: Optional[str] = None,\n",
    "                 arrow_paths: Optional[Sequence[Union[str, Path]]] = None,\n",
    "                 img_transform: Optional[Callable] = None,\n",
    "                 mask_transform: Optional[Callable] = None):\n",
    "        if (split is None) == (arrow_paths is None):\n",
    "            raise ValueError(\"Specify exactly one image source: either `split` (HF) OR `arrow_paths` (local).\")\n",
    "\n",
    "        # Image source\n",
    "        if split is not None:\n",
    "            ds_all = load_dataset(\"EPFL-ECEO/coralscapes\")\n",
    "            if split not in ds_all:\n",
    "                raise ValueError(f\"Split '{split}' not found. Available: {list(ds_all.keys())}\")\n",
    "            self.img_ds: HFDataset = ds_all[split]\n",
    "        else:\n",
    "            paths = [Path(p) for p in arrow_paths]\n",
    "            for p in paths:\n",
    "                if not p.exists():\n",
    "                    raise FileNotFoundError(f\"Arrow file not found: {p}\")\n",
    "            shards = [HFDataset.from_file(p.as_posix()) for p in paths]\n",
    "            self.img_ds = shards[0] if len(shards) == 1 else HFDataset.concatenate_datasets(shards)\n",
    "\n",
    "        # Masks\n",
    "        self.masks = _ParquetMasksByIndex(parquet_dir_or_paths)\n",
    "\n",
    "        self.img_tf = img_transform\n",
    "        self.mask_tf = mask_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ds)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        rec = self.img_ds[idx]\n",
    "        img: Image.Image = rec[\"image\"].convert(\"RGB\")\n",
    "        mask: Image.Image = self.masks.get_mask_pil(idx)  # keyed by dataset index\n",
    "\n",
    "        if self.img_tf is not None:\n",
    "            img = self.img_tf(img)\n",
    "        if self.mask_tf is not None:\n",
    "            mask = self.mask_tf(mask)\n",
    "        return img, mask\n",
    "\n",
    "\n",
    "# --- your instantiation lines (unchanged) ---\n",
    "TRAIN_PARQUET_DIR = r\"data_preprocessing\\coralscapes_export\\parquet\\train\"\n",
    "VAL_PARQUET_DIR   = r\"data_preprocessing\\coralscapes_export\\parquet\\validation\"\n",
    "TEST_PARQUET_DIR  = r\"data_preprocessing\\coralscapes_export\\parquet\\test\"\n",
    "\n",
    "CORALSCAPES_train = CoralScapesImagesMasks(split=\"train\", parquet_dir_or_paths=TRAIN_PARQUET_DIR)\n",
    "CORALSCAPES_val   = CoralScapesImagesMasks(split=\"validation\", parquet_dir_or_paths=VAL_PARQUET_DIR)\n",
    "CORALSCAPES_test  = CoralScapesImagesMasks(split=\"test\", parquet_dir_or_paths=TEST_PARQUET_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34905e8c",
   "metadata": {},
   "source": [
    "## Coral Bleaching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd3dd5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coral_bleaching_images = r\"g:\\.shortcut-targets-by-id\\1jGkNA1n0znoxKnQBHTJZuPgvkiu_OBM8\\coral_bleaching\\reef_support\\UNAL_BLEACHING_TAYRONA\\images\"\n",
    "coral_bleaching_combined_masks = r\"data_preprocessing/coralbleaching/combined_masks\"\n",
    "coral_bleaching_single_masks = r\"data_preprocessing/coralbleaching/single_masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7451e285",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joshu\\AppData\\Local\\Temp\\ipykernel_8460\\2167386991.py:9: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:209.)\n",
      "  return torch.from_numpy(a).permute(2,0,1).float()/255.0  # (3,H,W)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 3221, 4296]) torch.Size([8, 3, 3221, 4296])\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "def pil_to_tensor(img):\n",
    "    a = np.asarray(img.convert(\"RGB\"), dtype=np.uint8)  # (H,W,3)\n",
    "    return torch.from_numpy(a).permute(2,0,1).float()/255.0  # (3,H,W)\n",
    "\n",
    "class CoralBleachingDataset(Dataset):\n",
    "    def __init__(self, images_dir, combined_dir, single_dir):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.combined_dir = Path(combined_dir)\n",
    "        self.single_bleached = Path(single_dir) / \"bleached_blue\"\n",
    "        self.single_non = Path(single_dir) / \"non_bleached_red\"\n",
    "\n",
    "        imgs = []\n",
    "        for e in (\"*.png\",\"*.jpg\",\"*.jpeg\"):\n",
    "            imgs += list(self.images_dir.glob(e))\n",
    "        self.images = sorted(imgs)\n",
    "\n",
    "        self.pairs = self._match_pairs()\n",
    "\n",
    "    def _match_pairs(self):\n",
    "        def index_dir(d):\n",
    "            out={}\n",
    "            for e in (\"*.png\",\"*.jpg\",\"*.jpeg\"):\n",
    "                for p in d.glob(e): out[p.stem.lower()] = p\n",
    "            return out\n",
    "        cmb = index_dir(self.combined_dir)\n",
    "        ble = index_dir(self.single_bleached)\n",
    "        non = index_dir(self.single_non)\n",
    "\n",
    "        pairs=[]\n",
    "        for img in self.images:\n",
    "            key = img.stem.lower()\n",
    "            k_cmb = f\"{key}_combined\"\n",
    "            if k_cmb in cmb: pairs.append((img, cmb[k_cmb])); continue\n",
    "            cand = [p for k,p in ble.items() if k.startswith(key) or key in k]\n",
    "            if cand: pairs.append((img, cand[0])); continue\n",
    "            cand = [p for k,p in non.items() if k.startswith(key) or key in k]\n",
    "            if cand: pairs.append((img, cand[0]))\n",
    "        return pairs\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, i):\n",
    "        ip, mp = self.pairs[i]\n",
    "        x = pil_to_tensor(Image.open(ip))\n",
    "        y = pil_to_tensor(Image.open(mp))\n",
    "        return x, y  # (3,H,W), (3,H,W)\n",
    "\n",
    "def pad_collate(batch):\n",
    "    # batch: list of (img, mask) with varying H,W\n",
    "    imgs, masks = zip(*batch)\n",
    "    C = imgs[0].shape[0]\n",
    "    H = max(t.shape[1] for t in imgs)\n",
    "    W = max(t.shape[2] for t in imgs)\n",
    "    xb = torch.zeros(len(imgs), C, H, W, dtype=imgs[0].dtype)\n",
    "    yb = torch.zeros(len(masks), C, H, W, dtype=masks[0].dtype)\n",
    "    for i, (x, y) in enumerate(zip(imgs, masks)):\n",
    "        h, w = x.shape[1], x.shape[2]\n",
    "        xb[i, :, :h, :w] = x\n",
    "        yb[i, :, :h, :w] = y\n",
    "    return xb, yb\n",
    "\n",
    "# ---- use it ----\n",
    "dataset = CoralBleachingDataset(\n",
    "    images_dir=r\"g:\\.shortcut-targets-by-id\\1jGkNA1n0znoxKnQBHTJZuPgvkiu_OBM8\\coral_bleaching\\reef_support\\UNAL_BLEACHING_TAYRONA\\images\",\n",
    "    combined_dir=r\"data_preprocessing/coralbleaching/combined_masks\",\n",
    "    single_dir=r\"data_preprocessing/coralbleaching/single_masks\"\n",
    ")\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=0, collate_fn=pad_collate)\n",
    "\n",
    "xb, yb = next(iter(loader))\n",
    "print(xb.shape, yb.shape)  # -> (B,3,H_max,W_max) (B,3,H_max,W_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d8315f",
   "metadata": {},
   "source": [
    "# Combine ALL into ONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15160a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 2441, 3281]) torch.Size([8, 3, 2441, 3281])\n"
     ]
    }
   ],
   "source": [
    "# --- 1) Common PIL->tensor transform for both image and mask ---\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "def pil_to_tensor_rgb(img):\n",
    "    if img is None:\n",
    "        raise ValueError(\"Received None instead of a PIL.Image. Check your dataset/__getitem__.\")\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        return img  # already a tensor\n",
    "    a = np.asarray(img.convert(\"RGB\"), dtype=np.uint8)\n",
    "    return torch.from_numpy(a).permute(2,0,1).float() / 255.0\n",
    "\n",
    "\n",
    "class ToTensorPair:\n",
    "    \"\"\"Apply the same PIL->tensor conversion to (image, mask) pairs.\"\"\"\n",
    "    def __call__(self, img: Image.Image, mask: Image.Image) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        return pil_to_tensor_rgb(img), pil_to_tensor_rgb(mask)\n",
    "\n",
    "# --- 2) A tiny wrapper to enforce a uniform transform across heterogeneous datasets ---\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PairTransformWrapper(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps any (image, mask) dataset and applies (img_tf, mask_tf) before returning.\n",
    "    If the underlying dataset already returns tensors, you can pass identity lambdas.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ds: Dataset, img_tf=None, mask_tf=None):\n",
    "        self.base = base_ds\n",
    "        self.img_tf = img_tf\n",
    "        self.mask_tf = mask_tf\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        img, mask = self.base[idx]\n",
    "        if self.img_tf is not None:\n",
    "            img = self.img_tf(img)\n",
    "        if self.mask_tf is not None:\n",
    "            mask = self.mask_tf(mask)\n",
    "        return img, mask\n",
    "\n",
    "# --- 4) Standardize outputs: wrap PIL-returning datasets so *all* output tensors ---\n",
    "to_tensor = ToTensorPair()\n",
    "\n",
    "# Benthic sets likely return PIL unless you set transform; wrap them:\n",
    "BOLIVAR_t     = PairTransformWrapper(SEAFLOWER_BOLIVAR,     img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "COURTOWN_t    = PairTransformWrapper(SEAFLOWER_COURTOWN,    img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "PAC_USA_t     = PairTransformWrapper(SEAVIEW_PAC_USA,       img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "IDN_PHL_t     = PairTransformWrapper(SEAVIEW_IDN_PHL,       img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "PAC_AUS_t     = PairTransformWrapper(SEAVIEW_PAC_AUS,       img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "TETES_t       = PairTransformWrapper(TETES_PROVIDENCIA,     img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "ATL_t         = PairTransformWrapper(SEAVIEW_ATL,           img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "TAYRONA_t     = PairTransformWrapper(UNAL_BLEACHING_TAYRONA, img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "\n",
    "# Coralscapes (PIL) â†’ wrap as tensors too:\n",
    "CS_train_t    = PairTransformWrapper(CORALSCAPES_train,     img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "CS_val_t      = PairTransformWrapper(CORALSCAPES_val,       img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "CS_test_t     = PairTransformWrapper(CORALSCAPES_test,      img_tf=pil_to_tensor_rgb, mask_tf=pil_to_tensor_rgb)\n",
    "\n",
    "# CoralBleachingDataset already returns tensors (3,H,W). If so, no wrap needed:\n",
    "BLEACH_all_t  = dataset  # keep as-is\n",
    "# If you prefer symmetry, you can still wrap with identity:\n",
    "# BLEACH_all_t = PairTransformWrapper(dataset, img_tf=lambda x:x, mask_tf=lambda x:x)\n",
    "\n",
    "# --- 5) Concatenate EVERYTHING into one mega dataset ---\n",
    "from torch.utils.data import ConcatDataset\n",
    "\n",
    "ALL_DATA = ConcatDataset([\n",
    "    BOLIVAR_t, COURTOWN_t, PAC_USA_t, IDN_PHL_t, PAC_AUS_t, TETES_t, ATL_t, TAYRONA_t,\n",
    "    CS_train_t, CS_val_t, CS_test_t,\n",
    "    BLEACH_all_t,\n",
    "])\n",
    "\n",
    "# --- 6) Use your existing padded collate (handles variable sizes) ---\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader_all = DataLoader(\n",
    "    ALL_DATA,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    collate_fn=pad_collate,   # you already defined pad_collate earlier\n",
    ")\n",
    "\n",
    "xb, yb = next(iter(loader_all))\n",
    "print(xb.shape, yb.shape)  # (B,3,Hmax,Wmax) (B,3,Hmax,Wmax)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
