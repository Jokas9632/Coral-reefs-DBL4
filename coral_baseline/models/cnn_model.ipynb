{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affad121",
   "metadata": {},
   "source": [
    "### Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "934df6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Safer allocator settings (help fragmentation on Windows/WDDM)\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = (\n",
    "    \"backend:cudaMallocAsync,\"\n",
    "    \"expandable_segments:True,\"\n",
    "    \"max_split_size_mb:64,\"\n",
    "    \"garbage_collection_threshold:0.8\"\n",
    ")\n",
    "\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b83227",
   "metadata": {},
   "source": [
    "## Setting Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ffb980",
   "metadata": {},
   "source": [
    "### Step 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "777a6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Sequence, Optional, Callable, List, Union\n",
    "from io import BytesIO\n",
    "\n",
    "# EXACT Parquet files you provided (masks only)\n",
    "TRAIN_PARQUETS = [\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part001.parquet\",\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part002.parquet\",\n",
    "]\n",
    "VAL_PARQUETS = [\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\validation\\validation_part001.parquet\",\n",
    "]\n",
    "\n",
    "MASK_COLUMN = \"label_health_rgb_png\"  # mask PNG bytes column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f13097",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f0736cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, Dataset as HFDataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6ccfa5",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f5d8c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[check] TRAIN Parquet files:\n",
      "  - C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part001.parquet  -->  OK\n",
      "  - C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part002.parquet  -->  OK\n",
      "\n",
      "[check] VAL Parquet files:\n",
      "  - C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\validation\\validation_part001.parquet  -->  OK\n"
     ]
    }
   ],
   "source": [
    "def check_files_exist(paths: Sequence[str], tag: str):\n",
    "    print(f\"\\n[check] {tag} Parquet files:\")\n",
    "    ok = True\n",
    "    for p in paths:\n",
    "        pe = Path(p)\n",
    "        print(f\"  - {pe}  -->  {'OK' if pe.exists() else 'MISSING'}\")\n",
    "        ok &= pe.exists()\n",
    "    if not ok:\n",
    "        raise FileNotFoundError(f\"Some {tag} Parquet paths are missing.\")\n",
    "\n",
    "check_files_exist(TRAIN_PARQUETS, \"TRAIN\")\n",
    "check_files_exist(VAL_PARQUETS, \"VAL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90e4db1",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613eab84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[inspect] TRAIN\n",
      "  * C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part001.parquet\n",
      "    - rows: 1121\n",
      "    - columns: ['split', 'index', 'label_health_rgb_png']\n",
      "    - has 'index': True, has 'label_health_rgb_png': True\n",
      "    - sample mask type: bytes\n",
      "  * C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part002.parquet\n",
      "    - rows: 396\n",
      "    - columns: ['split', 'index', 'label_health_rgb_png']\n",
      "    - has 'index': True, has 'label_health_rgb_png': True\n",
      "    - sample mask type: bytes\n",
      "[inspect] TRAIN total rows across files: 1517\n",
      "\n",
      "[inspect] VAL\n",
      "  * C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\validation\\validation_part001.parquet\n",
      "    - rows: 166\n",
      "    - columns: ['split', 'index', 'label_health_rgb_png']\n",
      "    - has 'index': True, has 'label_health_rgb_png': True\n",
      "    - sample mask type: bytes\n",
      "[inspect] VAL total rows across files: 166\n"
     ]
    }
   ],
   "source": [
    "def inspect_parquet(paths: Sequence[str], tag: str, mask_col: str = MASK_COLUMN):\n",
    "    print(f\"\\n[inspect] {tag}\")\n",
    "    total_rows = 0\n",
    "    for p in paths:\n",
    "        tbl = pq.read_table(p)\n",
    "        n = tbl.num_rows\n",
    "        cols = tbl.column_names\n",
    "        total_rows += n\n",
    "        print(f\"  * {p}\")\n",
    "        print(f\"    - rows: {n}\")\n",
    "        print(f\"    - columns: {cols}\")\n",
    "        print(f\"    - has 'index': {'index' in cols}, has '{mask_col}': {mask_col in cols}\")\n",
    "        if \"index\" not in cols or mask_col not in cols:\n",
    "            raise ValueError(f\"{p} must contain 'index' and '{mask_col}'.\")\n",
    "        # peek first non-null mask value\n",
    "        col = tbl[mask_col]\n",
    "        sample = None\n",
    "        for i in range(n):\n",
    "            v = col[i].as_py()\n",
    "            if v is not None:\n",
    "                sample = v\n",
    "                break\n",
    "        print(f\"    - sample mask type: {type(sample).__name__ if sample is not None else 'None'}\")\n",
    "    print(f\"[inspect] {tag} total rows across files: {total_rows}\")\n",
    "\n",
    "inspect_parquet(TRAIN_PARQUETS, \"TRAIN\")\n",
    "inspect_parquet(VAL_PARQUETS, \"VAL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a75f8f",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e4a53b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[masks] index map size: 1517 from 2 file(s)\n",
      "[masks] index map size: 166 from 1 file(s)\n"
     ]
    }
   ],
   "source": [
    "class ParquetMasksByIndex:\n",
    "    def __init__(self, parquet_paths: Sequence[Union[str, Path]], column_png: str = MASK_COLUMN):\n",
    "        self._tables = []\n",
    "        for p in parquet_paths:\n",
    "            p = Path(p)\n",
    "            if not p.exists():\n",
    "                raise FileNotFoundError(f\"Parquet file not found: {p}\")\n",
    "            self._tables.append(pq.read_table(p))\n",
    "        for t in self._tables:\n",
    "            if \"index\" not in t.column_names or column_png not in t.column_names:\n",
    "                raise ValueError(f\"Parquet must have 'index' and '{column_png}'. Got: {t.column_names}\")\n",
    "        self._colname = column_png\n",
    "        # index → (table_id,row_id)\n",
    "        self._map = {}\n",
    "        for tid, t in enumerate(self._tables):\n",
    "            for rid, ds_idx in enumerate(t[\"index\"].to_pylist()):\n",
    "                self._map[int(ds_idx)] = (tid, rid)\n",
    "        print(f\"[masks] index map size: {len(self._map)} from {len(self._tables)} file(s)\")\n",
    "\n",
    "    def get_mask_pil(self, ds_index: int) -> Image.Image:\n",
    "        if ds_index not in self._map:\n",
    "            raise KeyError(f\"Index {ds_index} not found in masks.\")\n",
    "        tid, rid = self._map[ds_index]\n",
    "        cell = self._tables[tid][self._colname][rid].as_py()\n",
    "        if isinstance(cell, memoryview): cell = cell.tobytes()\n",
    "        elif isinstance(cell, bytearray): cell = bytes(cell)\n",
    "        return Image.open(BytesIO(cell)).convert(\"RGB\")\n",
    "\n",
    "masks_train = ParquetMasksByIndex(TRAIN_PARQUETS)\n",
    "masks_val   = ParquetMasksByIndex(VAL_PARQUETS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb0162c",
   "metadata": {},
   "source": [
    "### Step 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f48bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[images] loading EPFL-ECEO/coralscapes: 'train' + 'validation' splits...\n",
      "[images] sizes → train=1517, val=166\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n[images] loading EPFL-ECEO/coralscapes: 'train' + 'validation' splits...\")\n",
    "hf_all = load_dataset(\"EPFL-ECEO/coralscapes\")\n",
    "hf_train: HFDataset = hf_all[\"train\"]\n",
    "hf_val:   HFDataset = hf_all[\"validation\"]\n",
    "print(f\"[images] sizes → train={len(hf_train)}, val={len(hf_val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ced17e7",
   "metadata": {},
   "source": [
    "### Step 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23f6eada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_to_tensor_rgb(img: Image.Image) -> torch.Tensor:\n",
    "    arr = np.asarray(img.convert(\"RGB\"), dtype=np.uint8).copy()  # <- .copy() avoids the warning\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1).float() / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e9cad6",
   "metadata": {},
   "source": [
    "### Step 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1ebd8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[dataset] keeping 1517/1517 indices (mask-covered).\n",
      "[dataset] keeping 166/166 indices (mask-covered).\n"
     ]
    }
   ],
   "source": [
    "class CoralScapesImagesMasks(Dataset):\n",
    "    def __init__(self, img_ds: HFDataset, masks: ParquetMasksByIndex,\n",
    "                 img_transform: Optional[Callable] = None,\n",
    "                 mask_transform: Optional[Callable] = None,\n",
    "                 only_indices_with_masks: bool = True):\n",
    "        self.img_ds = img_ds\n",
    "        self.masks = masks\n",
    "        self.img_tf = img_transform\n",
    "        self.mask_tf = mask_transform\n",
    "        n = len(self.img_ds)\n",
    "        if only_indices_with_masks:\n",
    "            self.indices = [i for i in range(n) if i in self.masks._map]\n",
    "        else:\n",
    "            self.indices = list(range(n))\n",
    "        print(f\"[dataset] keeping {len(self.indices)}/{n} indices (mask-covered).\")\n",
    "\n",
    "    def __len__(self): return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, j: int):\n",
    "        idx = self.indices[j]\n",
    "        rec = self.img_ds[idx]\n",
    "        img: Image.Image = rec[\"image\"].convert(\"RGB\")\n",
    "        mask: Image.Image = self.masks.get_mask_pil(idx)\n",
    "        if self.img_tf is not None:  img = self.img_tf(img)\n",
    "        if self.mask_tf is not None: mask = self.mask_tf(mask)\n",
    "        return img, mask\n",
    "\n",
    "cs_train = CoralScapesImagesMasks(hf_train, masks_train, pil_to_tensor_rgb, pil_to_tensor_rgb)\n",
    "cs_val   = CoralScapesImagesMasks(hf_val,   masks_val,   pil_to_tensor_rgb, pil_to_tensor_rgb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd83834a",
   "metadata": {},
   "source": [
    "### Step 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c982993e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[probe] TRAIN: sample 0 → image (3, 1024, 2048) | mask (3, 1024, 2048)\n",
      "[probe] VAL: sample 0 → image (3, 1024, 2048) | mask (3, 1024, 2048)\n"
     ]
    }
   ],
   "source": [
    "def probe_one(ds: Dataset, name: str):\n",
    "    if len(ds) == 0:\n",
    "        print(f\"[probe] {name}: length=0 (no overlapping indices).\"); return\n",
    "    x, y = ds[0]\n",
    "    print(f\"[probe] {name}: sample 0 → image {tuple(x.shape)} | mask {tuple(y.shape)}\")\n",
    "\n",
    "probe_one(cs_train, \"TRAIN\")\n",
    "probe_one(cs_val,   \"VAL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92e4457",
   "metadata": {},
   "source": [
    "### Step 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dac589ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[batch] TRAIN xb (2, 3, 1024, 2048) | yb (2, 3, 1024, 2048)\n",
      "[batch] VAL   xb (2, 3, 1024, 2048) | yb (2, 3, 1024, 2048)\n"
     ]
    }
   ],
   "source": [
    "def pad_collate(batch):\n",
    "    imgs, masks = zip(*batch)\n",
    "    C = imgs[0].shape[0]\n",
    "    H = max(t.shape[1] for t in imgs); W = max(t.shape[2] for t in imgs)\n",
    "    xb = torch.zeros(len(imgs), C, H, W, dtype=imgs[0].dtype)\n",
    "    yb = torch.zeros(len(masks), C, H, W, dtype=masks[0].dtype)\n",
    "    for i, (x, y) in enumerate(zip(imgs, masks)):\n",
    "        h, w = x.shape[1], x.shape[2]\n",
    "        xb[i, :, :h, :w] = x\n",
    "        yb[i, :, :h, :w] = y\n",
    "    return xb, yb\n",
    "\n",
    "train_loader = DataLoader(cs_train, batch_size=2, shuffle=True,  num_workers=0, collate_fn=pad_collate)\n",
    "val_loader   = DataLoader(cs_val,   batch_size=2, shuffle=False, num_workers=0, collate_fn=pad_collate)\n",
    "\n",
    "xb, yb = next(iter(train_loader))\n",
    "print(f\"[batch] TRAIN xb {tuple(xb.shape)} | yb {tuple(yb.shape)}\")\n",
    "xb2, yb2 = next(iter(val_loader))\n",
    "print(f\"[batch] VAL   xb {tuple(xb2.shape)} | yb {tuple(yb2.shape)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08843e2a",
   "metadata": {},
   "source": [
    "### GPU Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1900f67b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.5.1+cu121 | CUDA: 12.1 | is_available: True\n",
      "torch file: c:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\__init__.py\n",
      "torchvision: 0.20.1+cu121\n",
      "torchaudio: 2.5.1+cu121\n",
      "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch, torchvision, torchaudio, sys\n",
    "print(\"torch:\", torch.__version__, \"| CUDA:\", torch.version.cuda, \"| is_available:\", torch.cuda.is_available())\n",
    "print(\"torch file:\", torch.__file__)\n",
    "print(\"torchvision:\", torchvision.__version__)\n",
    "print(\"torchaudio:\", torchaudio.__version__)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef8adef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA mem free: 3278 MiB / 4096 MiB\n"
     ]
    }
   ],
   "source": [
    "import os, gc, torch\n",
    "\n",
    "# Optional: allocator hints help fragmentation on Windows/WDDM\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:64,garbage_collection_threshold:0.8\"\n",
    "\n",
    "# Kill any previous big objects that might still hold GPU memory\n",
    "for name in list(globals().keys()):\n",
    "    if name in (\"model\",\"optimizer\",\"opt\",\"scaler\",\"train_loader\",\"val_loader\",\"cs_train\",\"cs_val\"):\n",
    "        try: del globals()[name]\n",
    "        except: pass\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    free, total = torch.cuda.mem_get_info()\n",
    "    print(f\"CUDA mem free: {free/1024**2:.0f} MiB / {total/1024**2:.0f} MiB\")\n",
    "else:\n",
    "    print(\"CUDA not available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3fd7f1",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bca6994b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda | NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "Model on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE, \"|\", torch.cuda.get_device_name(0) if DEVICE.type==\"cuda\" else \"\")\n",
    "\n",
    "class KerasLikeCNN_GAP(nn.Module):\n",
    "    def __init__(self, p_drop=0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=0),  # 128 -> 126\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                 # 126 -> 63\n",
    "            nn.Conv2d(32, 64, 3, padding=0), # 63 -> 61\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, 1), nn.ReLU(inplace=True),  # Dense(32) over maps\n",
    "            nn.Conv2d(32, 64, 1), nn.ReLU(inplace=True),  # Dense(64) over maps\n",
    "            nn.Conv2d(64, 128, 3, padding=0), nn.ReLU(inplace=True),  # 61 -> 59\n",
    "            nn.Dropout(p=p_drop),\n",
    "            nn.AdaptiveAvgPool2d(1),         # replaces giant Flatten\n",
    "        )\n",
    "        self.head = nn.Linear(128, 2)        # logits\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x).flatten(1)\n",
    "        return self.head(x)\n",
    "\n",
    "torch.backends.cudnn.benchmark = True  # let cuDNN pick fast kernels\n",
    "model = KerasLikeCNN_GAP(p_drop=0.5).to(DEVICE)\n",
    "print(\"Model on:\", next(model.parameters()).device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ad61b51",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_cls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mF\u001b[39;00m\n\u001b[0;32m      5\u001b[0m BATCH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m  \u001b[38;5;66;03m# if OOM, try 16 → 8\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[43mtrain_cls\u001b[49m, batch_size\u001b[38;5;241m=\u001b[39mBATCH, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,  num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m val_loader   \u001b[38;5;241m=\u001b[39m DataLoader(val_cls,   batch_size\u001b[38;5;241m=\u001b[39mBATCH, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      9\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_cls' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "BATCH = 32  # if OOM, try 16 → 8\n",
    "train_loader = DataLoader(train_cls, batch_size=BATCH, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_cls,   batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
    "\n",
    "# one mini-batch to confirm GPU path works\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb = xb.to(DEVICE, non_blocking=True)\n",
    "yb = yb.to(DEVICE, non_blocking=True)\n",
    "with autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "    logits = model(xb)\n",
    "    loss = criterion(logits, yb)\n",
    "scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "print(\"1 batch OK on\", DEVICE, \"| loss:\", float(loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49186d0b",
   "metadata": {},
   "source": [
    "### THESE CODES DONT GOT THAT GPU POWAAAHH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "266e74a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected cs_train/cs_val or train_loader/val_loader to exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m     vl \u001b[38;5;241m=\u001b[39m DataLoader(val_cls,   batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39mnum_workers)\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tl, vl\n\u001b[1;32m---> 36\u001b[0m train_loader, val_loader \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_build_loaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# --- (B) Keras-like CNN (mirrors your TF architecture) ---\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mKerasLikeCNN\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n",
      "Cell \u001b[1;32mIn[16], line 29\u001b[0m, in \u001b[0;36m_maybe_build_loaders\u001b[1;34m(batch_size, num_workers)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_loader, val_loader\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcs_train\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcs_val\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m():\n\u001b[1;32m---> 29\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected cs_train/cs_val or train_loader/val_loader to exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     30\u001b[0m train_cls \u001b[38;5;241m=\u001b[39m MaskToBinaryLabel128(cs_train, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n\u001b[0;32m     31\u001b[0m val_cls   \u001b[38;5;241m=\u001b[39m MaskToBinaryLabel128(cs_val,   size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected cs_train/cs_val or train_loader/val_loader to exist."
     ]
    }
   ],
   "source": [
    "# === Keras-like CNN training on CPU — no `.to()` anywhere ===\n",
    "import time\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# --- (A) Build loaders if missing (wrap cs_train/cs_val to 128x128 + binary labels) ---\n",
    "class MaskToBinaryLabel128(Dataset):\n",
    "    \"\"\"(image, mask) -> (image_128x128, label) with label=1 if blue>red, else 0.\"\"\"\n",
    "    def __init__(self, base_ds, size=128):\n",
    "        self.base = base_ds\n",
    "        self.size = size\n",
    "    def __len__(self): return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.base[idx]   # tensors in [0,1], shape (3,H,W)\n",
    "        if img.shape[-2:] != (self.size, self.size):\n",
    "            img  = F.interpolate(img.unsqueeze(0),  size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "            mask = F.interpolate(mask.unsqueeze(0), size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        red  = mask[0].sum().item()\n",
    "        blue = mask[2].sum().item()\n",
    "        label = 1 if blue > red else 0\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def _maybe_build_loaders(batch_size=32, num_workers=0):\n",
    "    if 'train_loader' in globals() and 'val_loader' in globals():\n",
    "        return train_loader, val_loader\n",
    "    if 'cs_train' not in globals() or 'cs_val' not in globals():\n",
    "        raise RuntimeError(\"Expected cs_train/cs_val or train_loader/val_loader to exist.\")\n",
    "    train_cls = MaskToBinaryLabel128(cs_train, size=128)\n",
    "    val_cls   = MaskToBinaryLabel128(cs_val,   size=128)\n",
    "    tl = DataLoader(train_cls, batch_size=batch_size, shuffle=True,  num_workers=num_workers)\n",
    "    vl = DataLoader(val_cls,   batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "    return tl, vl\n",
    "\n",
    "train_loader, val_loader = _maybe_build_loaders(batch_size=32, num_workers=0)\n",
    "\n",
    "# --- (B) Keras-like CNN (mirrors your TF architecture) ---\n",
    "class KerasLikeCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    128x128x3 -> Conv(32,3x3,valid) -> ReLU -> MaxPool(2)\n",
    "               -> Conv(64,3x3,valid) -> ReLU\n",
    "               -> 1x1 Conv(32) -> ReLU  (Dense on feature maps)\n",
    "               -> 1x1 Conv(64) -> ReLU  (Dense on feature maps)\n",
    "               -> Conv(128,3x3,valid) -> ReLU -> Dropout\n",
    "               -> Flatten -> Linear(2)\n",
    "    Flatten size for 128 input: 59*59*128 = 445,568 (matches your summary).\n",
    "    \"\"\"\n",
    "    def __init__(self, p_drop=0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=0),   # 128 -> 126\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                               # 126 -> 63\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=0),  # 63 -> 61\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=1, padding=0),  # \"Dense(32)\" on maps\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=1, padding=0),  # \"Dense(64)\" on maps\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=0), # 61 -> 59\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),                 # 128 x 59 x 59 -> 445,568\n",
    "            nn.Linear(128*59*59, 2),      # logits for 2 classes\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "model = KerasLikeCNN(p_drop=0.5)\n",
    "\n",
    "# --- (C) Training setup (no device moves) ---\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "EPOCHS = 45\n",
    "PATIENCE = 5\n",
    "MIN_DELTA = 1e-3\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5, min_delta=1e-3):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best = float('inf')\n",
    "        self.count = 0\n",
    "    def step(self, val_loss):\n",
    "        if self.best - val_loss > self.min_delta:\n",
    "            self.best = val_loss\n",
    "            self.count = 0\n",
    "            return False\n",
    "        self.count += 1\n",
    "        return self.count >= self.patience\n",
    "\n",
    "early = EarlyStopper(PATIENCE, MIN_DELTA)\n",
    "best_state = None\n",
    "\n",
    "# --- (D) Train / Validate loops (CPU only) ---\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum, correct, n = 0.0, 0, 0\n",
    "    for xb, yb in loader:\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(xb)                   # model & tensors on CPU\n",
    "            loss = criterion(logits, yb)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "        correct += (logits.argmax(1) == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "    return loss_sum / max(1, n), correct / max(1, n)\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
    "    dt = time.time() - t0\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} - loss: {tr_loss:.4f} - acc: {tr_acc:.4f} \"\n",
    "          f\"- val_loss: {va_loss:.4f} - val_acc: {va_acc:.4f} - {dt:.1f}s\")\n",
    "    if best_state is None or va_loss < (early.best - MIN_DELTA):\n",
    "        best_state = {k: v.detach().clone() for k, v in model.state_dict().items()}\n",
    "    if early.step(va_loss):\n",
    "        print(f\"Epoch {epoch}: early stopping (best val_loss={early.best:.4f})\")\n",
    "        break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best weights (by val_loss).\")\n",
    "\n",
    "# --- (E) Final validation score (like model.evaluate) ---\n",
    "model.eval()\n",
    "val_loss, val_acc, n = 0.0, 0.0, 0\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_loader:\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        val_loss += loss.item() * xb.size(0)\n",
    "        val_acc  += (logits.argmax(1) == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "val_loss /= max(1, n)\n",
    "val_acc  /= max(1, n)\n",
    "print(\"Validation Loss:\", val_loss)\n",
    "print(\"Validation Accuracy:\", val_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786d8c6e",
   "metadata": {},
   "source": [
    "### Step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d461abcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train len: 1517  |  val len: 166\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MaskToBinaryLabel128(Dataset):\n",
    "    \"\"\"\n",
    "    Wraps a (image_tensor, mask_tensor) dataset and returns:\n",
    "      image_128x128 (float tensor in [0,1], shape 3x128x128),\n",
    "      label (long, 0=non-bleached, 1=bleached) via blue-vs-red energy.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_ds, size=128):\n",
    "        self.base = base_ds\n",
    "        self.size = size\n",
    "\n",
    "    def __len__(self): \n",
    "        return len(self.base)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.base[idx]            # tensors: (3,H,W) in [0,1]\n",
    "        # resize to 128x128\n",
    "        if img.shape[-2:] != (self.size, self.size):\n",
    "            img  = F.interpolate(img.unsqueeze(0),  size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "            mask = F.interpolate(mask.unsqueeze(0), size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        # label: bleached if blue energy > red energy\n",
    "        red  = mask[0].sum().item()\n",
    "        blue = mask[2].sum().item()\n",
    "        label = 1 if blue > red else 0\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# build classification datasets (uses ONLY indices your Parquet provided, via cs_train/cs_val)\n",
    "train_cls = MaskToBinaryLabel128(cs_train, size=128)\n",
    "val_cls   = MaskToBinaryLabel128(cs_val,   size=128)\n",
    "\n",
    "# data loaders (no pad needed; fixed 128x128)\n",
    "BATCH = 32    # 128×128 is light; feel free to increase if memory allows\n",
    "NUM_WORKERS = 0\n",
    "train_loader = DataLoader(train_cls, batch_size=BATCH, shuffle=True,  num_workers=NUM_WORKERS)\n",
    "val_loader   = DataLoader(val_cls,   batch_size=BATCH, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(f\"train len: {len(train_cls)}  |  val len: {len(val_cls)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bdcc49",
   "metadata": {},
   "source": [
    "### Step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f27cb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 988,578\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class KerasLikeCNN(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch mirror of your Keras Sequential:\n",
    "      Conv2d(32,3x3,valid) -> MaxPool2d(2)\n",
    "      Conv2d(64,3x3,valid)\n",
    "      'Dense(32)' on feature maps -> 1x1 Conv(32)\n",
    "      'Dense(64)' on feature maps -> 1x1 Conv(64)\n",
    "      Conv2d(128,3x3,valid)\n",
    "      Dropout\n",
    "      Flatten\n",
    "      Linear(2)\n",
    "    For input 128x128, spatial dims evolve:\n",
    "      128 -> 126 (conv) -> 63 (pool) -> 61 (conv) -> 61 (1x1) -> 61 (1x1) -> 59 (conv)\n",
    "      flatten size = 59*59*128 = 445,568 (matches your summary)\n",
    "    \"\"\"\n",
    "    def __init__(self, p_drop=0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=0),   # 128 -> 126\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                               # 126 -> 63\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=0),  # 63 -> 61\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, kernel_size=1, padding=0),  # \"Dense(32)\" on maps\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=1, padding=0),  # \"Dense(64)\" on maps\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=0), # 61 -> 59\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=p_drop),\n",
    "        )\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),             # 128 x 59 x 59 -> 445,568\n",
    "            nn.Linear(128*59*59, 2),  # logits for 2 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "model = KerasLikeCNN(p_drop=0.5)\n",
    "# sanity: param count close to your Keras summary\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Trainable params: {n_params:,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a455e46",
   "metadata": {},
   "source": [
    "### Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751a2cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m PATIENCE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m        \u001b[38;5;66;03m# EarlyStopping like your Keras callback\u001b[39;00m\n\u001b[0;32m      8\u001b[0m MIN_DELTA \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m\n\u001b[1;32m---> 10\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mLR)\n\u001b[0;32m     12\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import time\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCHS = 45\n",
    "LR = 1e-3\n",
    "PATIENCE = 5        # EarlyStopping like your Keras callback\n",
    "MIN_DELTA = 1e-3\n",
    "\n",
    "model = model.to(DEVICE)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5, min_delta=1e-3):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.best = float(\"inf\")\n",
    "        self.count = 0\n",
    "    def step(self, val_loss):\n",
    "        if self.best - val_loss > self.min_delta:\n",
    "            self.best = val_loss\n",
    "            self.count = 0\n",
    "            return False  # don't stop\n",
    "        else:\n",
    "            self.count += 1\n",
    "            return self.count >= self.patience\n",
    "\n",
    "early = EarlyStopper(PATIENCE, MIN_DELTA)\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    if train: \n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "    total, correct, loss_sum, n = 0.0, 0, 0.0, 0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        if train:\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                opt.step()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "    return loss_sum / max(1, n), correct / max(1, n)\n",
    "\n",
    "best_state = None\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
    "    dt = time.time() - t0\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} \"\n",
    "          f\"- loss: {tr_loss:.4f} - acc: {tr_acc:.4f} \"\n",
    "          f\"- val_loss: {va_loss:.4f} - val_acc: {va_acc:.4f} \"\n",
    "          f\"- {dt:.1f}s\")\n",
    "    # Save best\n",
    "    if va_loss < (early.best - MIN_DELTA):\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    # Early stopping\n",
    "    if early.step(va_loss):\n",
    "        print(f\"Epoch {epoch}: early stopping (best val_loss={early.best:.4f})\")\n",
    "        break\n",
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best weights (by val_loss).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7597f18b",
   "metadata": {},
   "source": [
    "### Step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d07b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# === Train ===\u001b[39;00m\n\u001b[0;32m      2\u001b[0m DEVICE \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mKerasLikeCNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_ch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m opt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m)\n\u001b[0;32m      6\u001b[0m crit \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# === Train ===\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = KerasLikeCNN(in_ch=3, num_classes=2).to(DEVICE)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "EPOCHS = 10\n",
    "best_val = float(\"inf\")\n",
    "CKPT = \"keras_like_bleaching_cls.pth\"\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # -- train --\n",
    "    model.train()\n",
    "    total, correct, train_loss = 0, 0, 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        opt.zero_grad()\n",
    "        logits = model(xb)\n",
    "        loss = crit(logits, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        train_loss += loss.item() * yb.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "    train_loss /= total\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # -- validate --\n",
    "    model.eval()\n",
    "    v_total, v_correct, val_loss = 0, 0, 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "            logits = model(xb)\n",
    "            loss = crit(logits, yb)\n",
    "            val_loss += loss.item() * yb.size(0)\n",
    "            pred = logits.argmax(1)\n",
    "            v_correct += (pred == yb).sum().item()\n",
    "            v_total += yb.size(0)\n",
    "    val_loss /= v_total\n",
    "    val_acc = v_correct / v_total\n",
    "\n",
    "    print(f\"epoch {epoch:02d}/{EPOCHS} | \"\n",
    "          f\"train loss={train_loss:.4f} acc={train_acc:.3f} | \"\n",
    "          f\"val loss={val_loss:.4f} acc={val_acc:.3f}\")\n",
    "\n",
    "    if val_loss < best_val:\n",
    "        best_val = val_loss\n",
    "        torch.save({\"model\": model.state_dict(),\n",
    "                    \"epoch\": epoch,\n",
    "                    \"val_loss\": val_loss,\n",
    "                    \"val_acc\": val_acc}, CKPT)\n",
    "        print(f\"  ↳ saved best checkpoint to {CKPT}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern_ts_2E",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
