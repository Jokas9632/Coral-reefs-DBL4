{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58c4f1ce",
   "metadata": {},
   "source": [
    "### GPU Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c52ac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Safer allocator settings (help fragmentation on Windows/WDDM)\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = (\n",
    "    \"backend:cudaMallocAsync,\"\n",
    "    \"expandable_segments:True,\"\n",
    "    \"max_split_size_mb:64,\"\n",
    "    \"garbage_collection_threshold:0.8\"\n",
    ")\n",
    "\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e781afe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[masks] mapped 1517 indices from 2 file(s)\n",
      "[masks] mapped 166 indices from 1 file(s)\n",
      "[dataset] kept 1517/1517 indices (mask-covered).\n",
      "[dataset] kept 166/166 indices (mask-covered).\n",
      "[ready] train_cls len=1517 | val_cls len=166\n",
      "[loaders] train batches ≈ 48 | val batches ≈ 6\n",
      "[note] Loaders ready. Now run your model cell and training loop.\n"
     ]
    }
   ],
   "source": [
    "# === Recreate classification datasets + loaders (ONLY your Parquet files) ===\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from typing import Sequence, Optional, Callable, Union\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---- exact Parquet masks you provided ----\n",
    "TRAIN_PARQUETS = [\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part001.parquet\",\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part002.parquet\",\n",
    "]\n",
    "VAL_PARQUETS = [\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\validation\\validation_part001.parquet\",\n",
    "]\n",
    "MASK_COLUMN = \"label_health_rgb_png\"\n",
    "\n",
    "# ---- mask indexer: dataset index -> PNG ----\n",
    "class ParquetMasksByIndex:\n",
    "    def __init__(self, parquet_paths: Sequence[Union[str, Path]], column_png: str = MASK_COLUMN):\n",
    "        self._tables = [pq.read_table(Path(p)) for p in parquet_paths]\n",
    "        for t in self._tables:\n",
    "            if \"index\" not in t.column_names or column_png not in t.column_names:\n",
    "                raise ValueError(f\"Parquet must have 'index' and '{column_png}'. Got: {t.column_names}\")\n",
    "        self._col = column_png\n",
    "        self._map = {}\n",
    "        for tid, t in enumerate(self._tables):\n",
    "            for rid, ds_idx in enumerate(t[\"index\"].to_pylist()):\n",
    "                self._map[int(ds_idx)] = (tid, rid)\n",
    "        print(f\"[masks] mapped {len(self._map)} indices from {len(self._tables)} file(s)\")\n",
    "\n",
    "    def get_mask_pil(self, ds_index: int) -> Image.Image:\n",
    "        tid, rid = self._map[ds_index]\n",
    "        cell = self._tables[tid][self._col][rid].as_py()\n",
    "        if isinstance(cell, memoryview): cell = cell.tobytes()\n",
    "        elif isinstance(cell, bytearray): cell = bytes(cell)\n",
    "        return Image.open(BytesIO(cell)).convert(\"RGB\")\n",
    "\n",
    "# ---- HF images: EPFL-ECEO/coralscapes (train/validation) ----\n",
    "hf_all = load_dataset(\"EPFL-ECEO/coralscapes\")\n",
    "hf_train: HFDataset = hf_all[\"train\"]\n",
    "hf_val:   HFDataset = hf_all[\"validation\"]\n",
    "\n",
    "# ---- PIL -> tensor (copy() avoids \"non-writable\" warning) ----\n",
    "def pil_to_tensor_rgb(img: Image.Image) -> torch.Tensor:\n",
    "    arr = np.asarray(img.convert(\"RGB\"), dtype=np.uint8).copy()\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "# ---- bind images (HF) + masks (your Parquets only), keep only covered indices ----\n",
    "class CoralScapesImagesMasks(Dataset):\n",
    "    def __init__(self, img_ds: HFDataset, masks: ParquetMasksByIndex,\n",
    "                 img_transform: Optional[Callable] = None,\n",
    "                 mask_transform: Optional[Callable] = None):\n",
    "        self.img_ds = img_ds\n",
    "        self.masks = masks\n",
    "        self.img_tf = img_transform\n",
    "        self.mask_tf = mask_transform\n",
    "        n = len(self.img_ds)\n",
    "        self.indices = [i for i in range(n) if i in masks._map]\n",
    "        print(f\"[dataset] kept {len(self.indices)}/{n} indices (mask-covered).\")\n",
    "\n",
    "    def __len__(self): return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, j: int):\n",
    "        idx = self.indices[j]\n",
    "        rec = self.img_ds[idx]\n",
    "        img = rec[\"image\"].convert(\"RGB\")\n",
    "        mask = self.masks.get_mask_pil(idx)\n",
    "        if self.img_tf is not None:  img  = self.img_tf(img)\n",
    "        if self.mask_tf is not None: mask = self.mask_tf(mask)\n",
    "        return img, mask\n",
    "\n",
    "masks_train = ParquetMasksByIndex(TRAIN_PARQUETS, MASK_COLUMN)\n",
    "masks_val   = ParquetMasksByIndex(VAL_PARQUETS,   MASK_COLUMN)\n",
    "cs_train = CoralScapesImagesMasks(hf_train, masks_train, pil_to_tensor_rgb, pil_to_tensor_rgb)\n",
    "cs_val   = CoralScapesImagesMasks(hf_val,   masks_val,   pil_to_tensor_rgb, pil_to_tensor_rgb)\n",
    "\n",
    "# ---- classification wrapper → (image_128x128, label) ----\n",
    "class MaskToBinaryLabel128(Dataset):\n",
    "    def __init__(self, base_ds: Dataset, size=128):\n",
    "        self.base = base_ds\n",
    "        self.size = size\n",
    "    def __len__(self): return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.base[idx]  # tensors (3,H,W)\n",
    "        if img.shape[-2:] != (self.size, self.size):\n",
    "            img  = F.interpolate(img.unsqueeze(0),  size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "            mask = F.interpolate(mask.unsqueeze(0), size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        red  = mask[0].sum().item()\n",
    "        blue = mask[2].sum().item()\n",
    "        label = 1 if blue > red else 0  # bleached if blue energy > red\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_cls = MaskToBinaryLabel128(cs_train, size=128)\n",
    "val_cls   = MaskToBinaryLabel128(cs_val,   size=128)\n",
    "\n",
    "print(f\"[ready] train_cls len={len(train_cls)} | val_cls len={len(val_cls)}\")\n",
    "\n",
    "# ---- loaders (GPU-friendly: pin_memory). If a global `model` exists, run a 1-batch smoke test.\n",
    "BATCH = 32  # if OOM: 16 → 8\n",
    "train_loader = DataLoader(train_cls, batch_size=BATCH, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_cls,   batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(f\"[loaders] train batches ≈ {len(train_loader)} | val batches ≈ {len(val_loader)}\")\n",
    "\n",
    "if 'model' in globals():\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
    "    xb, yb = next(iter(train_loader))\n",
    "    xb = xb.to(DEVICE, non_blocking=True); yb = yb.to(DEVICE, non_blocking=True)\n",
    "    with autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "        logits = model(xb); loss = criterion(logits, yb)\n",
    "    scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "    print(\"[smoke] 1 batch OK on\", DEVICE, \"| loss:\", float(loss))\n",
    "else:\n",
    "    print(\"[note] Loaders ready. Now run your model cell and training loop.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d46e5c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda | NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "Model on: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_41532\\3707723666.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
      "c:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:64: UserWarning: backend:cudaMallocAsync ignores max_split_size_mb,roundup_power2_divisions, and garbage_collect_threshold. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\cuda\\CUDAAllocatorConfig.cpp:322.)\n",
      "  return data.pin_memory(device)\n",
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_41532\\3707723666.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke batch OK | loss: 0.65289306640625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE, \"|\", torch.cuda.get_device_name(0) if DEVICE.type==\"cuda\" else \"\")\n",
    "torch.backends.cudnn.benchmark = True  # speed boost\n",
    "\n",
    "# Keras-like CNN (same conv stack you showed; GAP replaces giant Flatten)\n",
    "class KerasLikeCNN_GAP(nn.Module):\n",
    "    def __init__(self, p_drop=0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=0),  # 128 -> 126\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                 # 126 -> 63\n",
    "            nn.Conv2d(32, 64, 3, padding=0), # 63 -> 61\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, 1), nn.ReLU(inplace=True),  # Dense(32) over maps\n",
    "            nn.Conv2d(32, 64, 1), nn.ReLU(inplace=True),  # Dense(64) over maps\n",
    "            nn.Conv2d(64, 128, 3, padding=0), nn.ReLU(inplace=True),  # 61 -> 59\n",
    "            nn.Dropout(p=p_drop),\n",
    "            nn.AdaptiveAvgPool2d(1),         # replaces huge Flatten(59*59*128)\n",
    "        )\n",
    "        self.head = nn.Linear(128, 2)        # binary logits\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x).flatten(1)      # (B,128,1,1) -> (B,128)\n",
    "        return self.head(x)\n",
    "\n",
    "model = KerasLikeCNN_GAP(p_drop=0.5).to(DEVICE)\n",
    "print(\"Model on:\", next(model.parameters()).device)\n",
    "\n",
    "# Optim, loss, AMP scaler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
    "\n",
    "# (optional) quick smoke test on one batch\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
    "with autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "    logits = model(xb); loss = criterion(logits, yb)\n",
    "scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "print(\"Smoke batch OK | loss:\", float(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "915ff6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label counts: Counter({0: 1470, 1: 47}) | val label counts: Counter({0: 153, 1: 13})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# 1) Build index lists the same way your datasets filtered them\n",
    "train_indices = [i for i in range(len(hf_train)) if i in masks_train._map]\n",
    "val_indices   = [i for i in range(len(hf_val))   if i in masks_val._map]\n",
    "\n",
    "def label_from_mask_bytes(mask_pil) -> int:\n",
    "    # unhealthy if blue channel energy > red channel energy\n",
    "    arr = np.asarray(mask_pil.convert(\"RGB\"), dtype=np.uint8)\n",
    "    return 1 if int(arr[...,2].sum()) > int(arr[...,0].sum()) else 0\n",
    "\n",
    "# 2) Precompute labels directly from original mask PNGs (no interpolation)\n",
    "y_train = []\n",
    "for idx in train_indices:\n",
    "    y_train.append(label_from_mask_bytes(masks_train.get_mask_pil(idx)))\n",
    "y_val = []\n",
    "for idx in val_indices:\n",
    "    y_val.append(label_from_mask_bytes(masks_val.get_mask_pil(idx)))\n",
    "\n",
    "cnt_tr = Counter(y_train); cnt_va = Counter(y_val)\n",
    "print(\"train label counts:\", cnt_tr, \"| val label counts:\", cnt_va)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee922238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[labels] train counts → healthy(0)=1471 | unhealthy(1)=46\n",
      "[CB weights] alpha: [0.5403340458869934, 1.4596658945083618]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_41532\\3430285082.py:41: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 75\u001b[0m\n\u001b[0;32m     72\u001b[0m best_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 75\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     76\u001b[0m     tr_loss, tr_acc \u001b[38;5;241m=\u001b[39m run_epoch(train_loader, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     77\u001b[0m     va_loss, va_acc \u001b[38;5;241m=\u001b[39m run_epoch(val_loader,   \u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "# 1) get training label counts (works with Images128WithLabels or any (x,y) dataset)\n",
    "def get_label_counts(ds):\n",
    "    if hasattr(ds, \"y\"):  # our Images128WithLabels exposes .y\n",
    "        y = ds.y.cpu().tolist()\n",
    "    else:\n",
    "        y = [int(ds[i][1]) for i in range(len(ds))]\n",
    "    n0 = sum(1 for t in y if t == 0); n1 = len(y) - n0\n",
    "    return n0, n1\n",
    "\n",
    "n0, n1 = get_label_counts(train_cls)\n",
    "print(f\"[labels] train counts → healthy(0)={n0} | unhealthy(1)={n1}\")\n",
    "\n",
    "# 2) Class-Balanced weights (effective number of samples, Cui et al.)\n",
    "def class_balanced_weights(n_per_class, beta=0.99):\n",
    "    w = []\n",
    "    for n in n_per_class:\n",
    "        n = max(1, n)\n",
    "        w_c = (1 - beta) / (1 - beta**n)\n",
    "        w.append(w_c)\n",
    "    # normalize so mean weight ≈ 1 (helps keep loss scale stable)\n",
    "    m = sum(w)/len(w)\n",
    "    return torch.tensor([wc/m for wc in w], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "cb_alpha = class_balanced_weights([n0, n1], beta=0.99)\n",
    "print(\"[CB weights] alpha:\", cb_alpha.tolist())\n",
    "\n",
    "# 3) Focal Cross-Entropy (multiclass) with class-balanced alpha\n",
    "def focal_ce_loss(logits, target, alpha=None, gamma=1.0):\n",
    "    # CE per-sample\n",
    "    ce = F.cross_entropy(logits, target, reduction=\"none\")\n",
    "    # p_t = prob of the true class\n",
    "    pt = F.softmax(logits, dim=1).gather(1, target.view(-1,1)).squeeze(1).clamp_(1e-6, 1-1e-6)\n",
    "    loss = ce * ((1 - pt) ** gamma)\n",
    "    if alpha is not None:\n",
    "        loss = loss * alpha[target]\n",
    "    return loss.mean()\n",
    "\n",
    "# 5) optimizer + AMP scaler (keep your existing model / GAP head)\n",
    "criterion = lambda logits, y: focal_ce_loss(logits, y, alpha=cb_alpha, gamma=1.0)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-4)   # slightly lower LR for stability\n",
    "scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# 6) train with early stopping by val loss\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=6, min_delta=1e-3):\n",
    "        self.patience = patience; self.min_delta = min_delta\n",
    "        self.best = float(\"inf\"); self.count = 0\n",
    "    def step(self, v):\n",
    "        if self.best - v > self.min_delta:\n",
    "            self.best = v; self.count = 0; return False\n",
    "        self.count += 1; return self.count >= self.patience\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum = correct = n = 0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True); yb = yb.to(DEVICE, non_blocking=True)\n",
    "        if train: opt.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train), autocast(\"cuda\", enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "        correct  += (logits.argmax(1) == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "    return loss_sum/max(1,n), correct/max(1,n)\n",
    "\n",
    "EPOCHS = 2\n",
    "early = EarlyStopper(patience=6, min_delta=1e-3)\n",
    "best_state = None\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   False)\n",
    "    print(f\"Epoch {ep:02d}/{EPOCHS} - loss:{tr_loss:.4f} - acc:{tr_acc:.4f} - val_loss:{va_loss:.4f} - val_acc:{va_acc:.4f} - {time.time()-t0:.1f}s\")\n",
    "    if best_state is None or va_loss < (early.best - 1e-3):\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    if early.step(va_loss):\n",
    "        print(f\"Epoch {ep}: early stopping (best val_loss={early.best:.4f})\")\n",
    "        break\n",
    "\n",
    "if best_state: \n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best weights.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ffc0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_val_probs_and_labels(model, loader):\n",
    "    model.eval()\n",
    "    probs = []; labels = []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "        with autocast(\"cuda\", enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            p = F.softmax(logits, dim=1)[:, 1]  # P(class=1 = unhealthy)\n",
    "        probs.append(p.cpu()); labels.append(yb.cpu())\n",
    "    return torch.cat(probs), torch.cat(labels)\n",
    "\n",
    "def metrics_from_preds(y_true, y_pred):\n",
    "    cm = torch.zeros(2,2, dtype=torch.int64)\n",
    "    for t,p in zip(y_true, y_pred): cm[t,p]+=1\n",
    "    def prf(c):\n",
    "        tp=cm[c,c].item(); fp=cm[:,c].sum().item()-tp; fn=cm[c,:].sum().item()-tp\n",
    "        prec = tp / max(1, tp+fp); rec = tp / max(1, tp+fn)\n",
    "        f1 = 0.0 if prec+rec==0 else 2*prec*rec/(prec+rec)\n",
    "        return prec, rec, f1\n",
    "    p0,r0,f0 = prf(0); p1,r1,f1 = prf(1)\n",
    "    macro_f1 = 0.5*(f0+f1)\n",
    "    acc = (y_true == y_pred).float().mean().item()\n",
    "    return {\"acc\":acc, \"macro_f1\":macro_f1, \"cm\":cm, \"per\":{\"healthy\":(p0,r0,f0),\"unhealthy\":(p1,r1,f1)}}\n",
    "\n",
    "# 1) collect probabilities for class=1 on the val set\n",
    "probs, y_true = collect_val_probs_and_labels(model, val_loader)\n",
    "\n",
    "# 2) sweep thresholds and pick the one that maximizes macro-F1 (balanced performance)\n",
    "best = {\"t\":0.5, \"macro_f1\":-1}\n",
    "for t in torch.linspace(0.1, 0.9, steps=17):  # 0.1 → 0.9 step 0.05\n",
    "    y_pred = (probs >= t).long()\n",
    "    m = metrics_from_preds(y_true, y_pred)\n",
    "    if m[\"macro_f1\"] > best[\"macro_f1\"]:\n",
    "        best = {\"t\": float(t), \"macro_f1\": m[\"macro_f1\"], \"metrics\": m}\n",
    "\n",
    "m = best[\"metrics\"]; cm = m[\"cm\"].numpy()\n",
    "(p0,r0,f0) = m[\"per\"][\"healthy\"]; (p1,r1,f1) = m[\"per\"][\"unhealthy\"]\n",
    "print(f\"\\nBest threshold t={best['t']:.2f} (by macro-F1={best['macro_f1']:.3f})\")\n",
    "print(f\"Overall: acc={m['acc']:.3f} | macro-F1={m['macro_f1']:.3f}\")\n",
    "print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "#print(f\"            pred: healthy   pred: unhealthy\")\n",
    "#print(f\"true healthy     {cm[0,0]:>6}          {cm[0,1]:>6}\")\n",
    "#print(f\"true unhealthy   {cm[1,0]:>6}          {cm[1,1]:>6}\")\n",
    "print(f\"healthy   | precision={p0:.3f} | recall={r0:.3f} | f1={f0:.3f}\")\n",
    "print(f\"unhealthy | precision={p1:.3f} | recall={r1:.3f} | f1={f1:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern_ts_2E",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
