{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74cc899d",
   "metadata": {},
   "source": [
    "### GPU Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb9eac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Safer allocator settings (help fragmentation on Windows/WDDM)\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = (\n",
    "    \"backend:cudaMallocAsync,\"\n",
    "    \"expandable_segments:True,\"\n",
    "    \"max_split_size_mb:64,\"\n",
    "    \"garbage_collection_threshold:0.8\"\n",
    ")\n",
    "\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd4ade4",
   "metadata": {},
   "source": [
    "### CNN Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f0802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[masks] mapped 1517 indices from 2 file(s)\n",
      "[masks] mapped 166 indices from 1 file(s)\n",
      "[dataset] kept 1517/1517 indices (mask-covered).\n",
      "[dataset] kept 166/166 indices (mask-covered).\n",
      "[ready] train_cls len=1517 | val_cls len=166\n",
      "[loaders] train batches ≈ 48 | val batches ≈ 6\n",
      "[note] Loaders ready. Now run your model cell and training loop.\n"
     ]
    }
   ],
   "source": [
    "# === Recreate classification datasets + loaders (ONLY your Parquet files) ===\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from typing import Sequence, Optional, Callable, Union\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---- exact Parquet masks you provided ----\n",
    "TRAIN_PARQUETS = [\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part001.parquet\",\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part002.parquet\",\n",
    "]\n",
    "VAL_PARQUETS = [\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\validation\\validation_part001.parquet\",\n",
    "]\n",
    "MASK_COLUMN = \"label_health_rgb_png\"\n",
    "\n",
    "# ---- mask indexer: dataset index -> PNG ----\n",
    "class ParquetMasksByIndex:\n",
    "    def __init__(self, parquet_paths: Sequence[Union[str, Path]], column_png: str = MASK_COLUMN):\n",
    "        self._tables = [pq.read_table(Path(p)) for p in parquet_paths]\n",
    "        for t in self._tables:\n",
    "            if \"index\" not in t.column_names or column_png not in t.column_names:\n",
    "                raise ValueError(f\"Parquet must have 'index' and '{column_png}'. Got: {t.column_names}\")\n",
    "        self._col = column_png\n",
    "        self._map = {}\n",
    "        for tid, t in enumerate(self._tables):\n",
    "            for rid, ds_idx in enumerate(t[\"index\"].to_pylist()):\n",
    "                self._map[int(ds_idx)] = (tid, rid)\n",
    "        print(f\"[masks] mapped {len(self._map)} indices from {len(self._tables)} file(s)\")\n",
    "\n",
    "    def get_mask_pil(self, ds_index: int) -> Image.Image:\n",
    "        tid, rid = self._map[ds_index]\n",
    "        cell = self._tables[tid][self._col][rid].as_py()\n",
    "        if isinstance(cell, memoryview): cell = cell.tobytes()\n",
    "        elif isinstance(cell, bytearray): cell = bytes(cell)\n",
    "        return Image.open(BytesIO(cell)).convert(\"RGB\")\n",
    "\n",
    "# ---- HF images: EPFL-ECEO/coralscapes (train/validation) ----\n",
    "hf_all = load_dataset(\"EPFL-ECEO/coralscapes\")\n",
    "hf_train: HFDataset = hf_all[\"train\"]\n",
    "hf_val:   HFDataset = hf_all[\"validation\"]\n",
    "\n",
    "# ---- PIL -> tensor (copy() avoids \"non-writable\" warning) ----\n",
    "def pil_to_tensor_rgb(img: Image.Image) -> torch.Tensor:\n",
    "    arr = np.asarray(img.convert(\"RGB\"), dtype=np.uint8).copy()\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "# ---- bind images (HF) + masks (your Parquets only), keep only covered indices ----\n",
    "class CoralScapesImagesMasks(Dataset):\n",
    "    def __init__(self, img_ds: HFDataset, masks: ParquetMasksByIndex,\n",
    "                 img_transform: Optional[Callable] = None,\n",
    "                 mask_transform: Optional[Callable] = None):\n",
    "        self.img_ds = img_ds\n",
    "        self.masks = masks\n",
    "        self.img_tf = img_transform\n",
    "        self.mask_tf = mask_transform\n",
    "        n = len(self.img_ds)\n",
    "        self.indices = [i for i in range(n) if i in masks._map]\n",
    "        print(f\"[dataset] kept {len(self.indices)}/{n} indices (mask-covered).\")\n",
    "\n",
    "    def __len__(self): return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, j: int):\n",
    "        idx = self.indices[j]\n",
    "        rec = self.img_ds[idx]\n",
    "        img = rec[\"image\"].convert(\"RGB\")\n",
    "        mask = self.masks.get_mask_pil(idx)\n",
    "        if self.img_tf is not None:  img  = self.img_tf(img)\n",
    "        if self.mask_tf is not None: mask = self.mask_tf(mask)\n",
    "        return img, mask\n",
    "\n",
    "masks_train = ParquetMasksByIndex(TRAIN_PARQUETS, MASK_COLUMN)\n",
    "masks_val   = ParquetMasksByIndex(VAL_PARQUETS,   MASK_COLUMN)\n",
    "cs_train = CoralScapesImagesMasks(hf_train, masks_train, pil_to_tensor_rgb, pil_to_tensor_rgb)\n",
    "cs_val   = CoralScapesImagesMasks(hf_val,   masks_val,   pil_to_tensor_rgb, pil_to_tensor_rgb)\n",
    "\n",
    "# ---- classification wrapper → (image_128x128, label) ----\n",
    "class MaskToBinaryLabel128(Dataset):\n",
    "    def __init__(self, base_ds: Dataset, size=128):\n",
    "        self.base = base_ds\n",
    "        self.size = size\n",
    "    def __len__(self): return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.base[idx]  # tensors (3,H,W)\n",
    "        if img.shape[-2:] != (self.size, self.size):\n",
    "            img  = F.interpolate(img.unsqueeze(0),  size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "            mask = F.interpolate(mask.unsqueeze(0), size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        red  = mask[0].sum().item()\n",
    "        blue = mask[2].sum().item()\n",
    "        label = 1 if blue > red else 0  # bleached if blue energy > red\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_cls = MaskToBinaryLabel128(cs_train, size=128)\n",
    "val_cls   = MaskToBinaryLabel128(cs_val,   size=128)\n",
    "\n",
    "print(f\"[ready] train_cls len={len(train_cls)} | val_cls len={len(val_cls)}\")\n",
    "\n",
    "# ---- loaders (GPU-friendly: pin_memory). If a global `model` exists, run a 1-batch smoke test.\n",
    "BATCH = 32  # if OOM: 16 → 8\n",
    "train_loader = DataLoader(train_cls, batch_size=BATCH, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_cls,   batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(f\"[loaders] train batches ≈ {len(train_loader)} | val batches ≈ {len(val_loader)}\")\n",
    "\n",
    "if 'model' in globals():\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
    "    xb, yb = next(iter(train_loader))\n",
    "    xb = xb.to(DEVICE, non_blocking=True); yb = yb.to(DEVICE, non_blocking=True)\n",
    "    with autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "        logits = model(xb); loss = criterion(logits, yb)\n",
    "    scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "    print(\"[smoke] 1 batch OK on\", DEVICE, \"| loss:\", float(loss))\n",
    "else:\n",
    "    print(\"[note] Loaders ready. Now run your model cell and training loop.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c4d07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda | NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "Model on: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\3707723666.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
      "c:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:64: UserWarning: backend:cudaMallocAsync ignores max_split_size_mb,roundup_power2_divisions, and garbage_collect_threshold. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\cuda\\CUDAAllocatorConfig.cpp:322.)\n",
      "  return data.pin_memory(device)\n",
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\3707723666.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke batch OK | loss: 0.72027587890625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE, \"|\", torch.cuda.get_device_name(0) if DEVICE.type==\"cuda\" else \"\")\n",
    "torch.backends.cudnn.benchmark = True  # speed boost\n",
    "\n",
    "# Keras-like CNN (same conv stack you showed; GAP replaces giant Flatten)\n",
    "class KerasLikeCNN_GAP(nn.Module):\n",
    "    def __init__(self, p_drop=0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=0),  # 128 -> 126\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                 # 126 -> 63\n",
    "            nn.Conv2d(32, 64, 3, padding=0), # 63 -> 61\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, 1), nn.ReLU(inplace=True),  # Dense(32) over maps\n",
    "            nn.Conv2d(32, 64, 1), nn.ReLU(inplace=True),  # Dense(64) over maps\n",
    "            nn.Conv2d(64, 128, 3, padding=0), nn.ReLU(inplace=True),  # 61 -> 59\n",
    "            nn.Dropout(p=p_drop),\n",
    "            nn.AdaptiveAvgPool2d(1),         # replaces huge Flatten(59*59*128)\n",
    "        )\n",
    "        self.head = nn.Linear(128, 2)        # binary logits\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x).flatten(1)      # (B,128,1,1) -> (B,128)\n",
    "        return self.head(x)\n",
    "\n",
    "model = KerasLikeCNN_GAP(p_drop=0.5).to(DEVICE)\n",
    "print(\"Model on:\", next(model.parameters()).device)\n",
    "\n",
    "# Optim, loss, AMP scaler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
    "\n",
    "# (optional) quick smoke test on one batch\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
    "with autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "    logits = model(xb); loss = criterion(logits, yb)\n",
    "scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "print(\"Smoke batch OK | loss:\", float(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a01a469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\1664916854.py:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.set_grad_enabled(train), autocast(enabled=(DEVICE.type==\"cuda\")):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     36\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 37\u001b[0m     tr_loss, tr_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     va_loss, va_acc \u001b[38;5;241m=\u001b[39m run_epoch(val_loader,   train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m     dt \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36mrun_epoch\u001b[1;34m(loader, train)\u001b[0m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     15\u001b[0m loss_sum \u001b[38;5;241m=\u001b[39m correct \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 90\u001b[0m, in \u001b[0;36mMaskToBinaryLabel128.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 90\u001b[0m     img, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# tensors (3,H,W)\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize):\n\u001b[0;32m     92\u001b[0m         img  \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(img\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m),  size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 71\u001b[0m, in \u001b[0;36mCoralScapesImagesMasks.__getitem__\u001b[1;34m(self, j)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, j: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m     70\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[j]\n\u001b[1;32m---> 71\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     72\u001b[0m     img \u001b[38;5;241m=\u001b[39m rec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasks\u001b[38;5;241m.\u001b[39mget_mask_pil(idx)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\arrow_dataset.py:2862\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2860\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolars\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2861\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m-> 2862\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\arrow_dataset.py:2844\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2842\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2843\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m-> 2844\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[0;32m   2846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:658\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    656\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:411\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:460\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    459\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[1;32m--> 460\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:224\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\features.py:2097\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[1;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[0;32m   2082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[0;32m   2084\u001b[0m \n\u001b[0;32m   2085\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m-> 2097\u001b[0m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2098\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   2099\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m   2100\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[0;32m   2101\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[0;32m   2102\u001b[0m         )\n\u001b[0;32m   2103\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\features.py:1409\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[1;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m-> 1409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\image.py:193\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[1;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[1;32m--> 193\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\PIL\\ImageFile.py:390\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    389\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 390\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5, min_delta=1e-3):\n",
    "        self.patience = patience; self.min_delta = min_delta\n",
    "        self.best = float(\"inf\"); self.count = 0\n",
    "    def step(self, val_loss):\n",
    "        if self.best - val_loss > self.min_delta:\n",
    "            self.best = val_loss; self.count = 0; return False\n",
    "        self.count += 1; return self.count >= self.patience\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum = correct = n = 0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        if train: opt.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train), autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "        correct  += (logits.argmax(1) == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "    return loss_sum/max(1,n), correct/max(1,n)\n",
    "\n",
    "EPOCHS = 5\n",
    "early = EarlyStopper(patience=5, min_delta=1e-3)\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
    "    dt = time.time() - t0\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} - loss: {tr_loss:.4f} - acc: {tr_acc:.4f} \"\n",
    "          f\"- val_loss: {va_loss:.4f} - val_acc: {va_acc:.4f} - {dt:.1f}s\")\n",
    "    if best_state is None or va_loss < (early.best - 1e-3):\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    if early.step(va_loss):\n",
    "        print(f\"Epoch {epoch}: early stopping (best val_loss={early.best:.4f})\")\n",
    "        break\n",
    "\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best weights.\")\n",
    "\n",
    "# Final validation (like model.evaluate)\n",
    "model.eval()\n",
    "val_loss = val_acc = n = 0\n",
    "with torch.no_grad(), autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "    for xb, yb in val_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        val_loss += loss.item() * xb.size(0)\n",
    "        val_acc  += (logits.argmax(1) == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "val_loss /= max(1, n)\n",
    "val_acc  /= max(1, n)\n",
    "print(\"Validation Loss:\", round(val_loss, 4))\n",
    "print(\"Validation Accuracy:\", round(val_acc, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a170e",
   "metadata": {},
   "source": [
    "### with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482ad823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts -> healthy(0): 1339 | unhealthy(1): 178\n",
      "class weights: [0.5665, 4.2612]\n",
      "[loaders] train batches ≈ 48 | val batches ≈ 6\n"
     ]
    }
   ],
   "source": [
    "# === Per-class setup (0=healthy, 1=unhealthy/bleached) ===\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "CLASS_NAMES = {0: \"healthy\", 1: \"unhealthy\"}  # 1=bleached/unhealthy\n",
    "\n",
    "def label_from_mask_fast(mask_pil: Image.Image) -> int:\n",
    "    arr = np.asarray(mask_pil.convert(\"RGB\"), dtype=np.uint8)\n",
    "    red  = int(arr[..., 0].sum())\n",
    "    blue = int(arr[..., 2].sum())\n",
    "    return 1 if blue > red else 0  # unhealthy if blue dominates\n",
    "\n",
    "# Build labels aligned with train_cls order (no need to re-open images)\n",
    "train_labels = []\n",
    "for j in range(len(train_cls)):\n",
    "    idx = cs_train.indices[j]\n",
    "    m = masks_train.get_mask_pil(idx)\n",
    "    train_labels.append(label_from_mask_fast(m))\n",
    "\n",
    "cnt = Counter(train_labels)\n",
    "n0, n1 = cnt.get(0, 0), cnt.get(1, 0)\n",
    "print(f\"class counts -> healthy(0): {n0} | unhealthy(1): {n1}\")\n",
    "\n",
    "# Class weights inversely proportional to frequency\n",
    "total = len(train_labels)\n",
    "w0 = total / (2.0 * max(1, n0))\n",
    "w1 = total / (2.0 * max(1, n1))\n",
    "class_weights = torch.tensor([w0, w1], dtype=torch.float32, device=DEVICE)\n",
    "print(\"class weights:\", [round(float(w0), 4), round(float(w1), 4)])\n",
    "\n",
    "# Weighted sampler for balanced minibatches\n",
    "sample_weights = [w0 if y == 0 else w1 for y in train_labels]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Rebuild loaders (pin_memory for GPU IO). Keep val shuffled=False\n",
    "BATCH = 32  # drop to 16/8 if VRAM is tight\n",
    "train_loader = DataLoader(train_cls, batch_size=BATCH, sampler=sampler, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_cls,   batch_size=BATCH, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "print(f\"[loaders] train batches ≈ {len(train_loader)} | val batches ≈ {len(val_loader)}\")\n",
    "\n",
    "# Re-define criterion with class weights (affects loss per class)\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# (Optional) reset optimizer to start fresh with the new criterion\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74816316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\3800905205.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.set_grad_enabled(train), autocast(enabled=(DEVICE.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/3 - loss: 0.3694 - acc: 0.4984 - val_loss: 0.9613 - val_acc: 0.2711 - 354.3s\n",
      "Epoch 02/3 - loss: 0.3717 - acc: 0.4937 - val_loss: 0.8740 - val_acc: 0.2711 - 316.0s\n",
      "Epoch 03/3 - loss: 0.3557 - acc: 0.5208 - val_loss: 1.0742 - val_acc: 0.2711 - 315.5s\n",
      "Loaded best weights.\n",
      "\n",
      "=== Validation (per class) ===\n",
      "Overall: loss=0.8739 | acc=0.2711\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "            pred: healthy   pred: unhealthy\n",
      "true healthy          0             121\n",
      "true unhealthy        0              45\n",
      "\n",
      "Per-class metrics:\n",
      "  healthy    | precision=0.000 | recall=0.000 | f1=0.000 | support=121\n",
      "  unhealthy  | precision=0.271 | recall=1.000 | f1=0.427 | support=45\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# If you didn't define a scaler yet:\n",
    "try:\n",
    "    scaler\n",
    "except NameError:\n",
    "    scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5, min_delta=1e-3):\n",
    "        self.patience = patience; self.min_delta = min_delta\n",
    "        self.best = float(\"inf\"); self.count = 0\n",
    "    def step(self, val_loss):\n",
    "        if self.best - val_loss > self.min_delta:\n",
    "            self.best = val_loss; self.count = 0; return False\n",
    "        self.count += 1; return self.count >= self.patience\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum = correct = n = 0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        if train: opt.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train), autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "        correct  += (logits.argmax(1) == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "    return loss_sum/max(1,n), correct/max(1,n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_with_metrics(model, loader):\n",
    "    model.eval()\n",
    "    n = 0; loss_sum = 0\n",
    "    all_true = []; all_pred = []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss_sum += loss.item() * xb.size(0); n += xb.size(0)\n",
    "        all_true.append(yb.cpu()); all_pred.append(logits.argmax(1).cpu())\n",
    "    y_true = torch.cat(all_true)\n",
    "    y_pred = torch.cat(all_pred)\n",
    "    # Confusion matrix (2x2): rows=true, cols=pred\n",
    "    cm = torch.zeros(2, 2, dtype=torch.int64)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[t, p] += 1\n",
    "    # Per-class precision/recall/F1\n",
    "    per_class = {}\n",
    "    for c in [0, 1]:\n",
    "        tp = cm[c, c].item()\n",
    "        fp = cm[:, c].sum().item() - tp\n",
    "        fn = cm[c, :].sum().item() - tp\n",
    "        precision = tp / max(1, tp + fp)\n",
    "        recall    = tp / max(1, tp + fn)\n",
    "        f1        = 0.0 if (precision + recall) == 0 else 2 * precision * recall / (precision + recall)\n",
    "        per_class[c] = {\n",
    "            \"name\": CLASS_NAMES[c],\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"support\": cm[c, :].sum().item(),\n",
    "        }\n",
    "    acc = (y_true == y_pred).float().mean().item()\n",
    "    return {\"loss\": loss_sum/max(1,n), \"acc\": acc, \"cm\": cm, \"per_class\": per_class}\n",
    "\n",
    "# ---- Train with early stopping, save best by val loss ----\n",
    "EPOCHS = 3\n",
    "early = EarlyStopper(patience=5, min_delta=1e-3)\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} - loss: {tr_loss:.4f} - acc: {tr_acc:.4f} \"\n",
    "          f\"- val_loss: {va_loss:.4f} - val_acc: {va_acc:.4f} - {time.time()-t0:.1f}s\")\n",
    "    if best_state is None or va_loss < (early.best - 1e-3):\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    if early.step(va_loss):\n",
    "        print(f\"Epoch {epoch}: early stopping (best val_loss={early.best:.4f})\")\n",
    "        break\n",
    "\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best weights.\")\n",
    "\n",
    "# ---- Final evaluation with PER-CLASS metrics ----\n",
    "res = evaluate_with_metrics(model, val_loader)\n",
    "print(\"\\n=== Validation (per class) ===\")\n",
    "print(f\"Overall: loss={res['loss']:.4f} | acc={res['acc']:.4f}\")\n",
    "cm = res[\"cm\"].numpy()\n",
    "print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "print(f\"            pred: healthy   pred: unhealthy\")\n",
    "print(f\"true healthy     {cm[0,0]:>6}          {cm[0,1]:>6}\")\n",
    "print(f\"true unhealthy   {cm[1,0]:>6}          {cm[1,1]:>6}\")\n",
    "print(\"\\nPer-class metrics:\")\n",
    "for c in [0, 1]:\n",
    "    m = res[\"per_class\"][c]\n",
    "    print(f\"  {m['name']:<10} | precision={m['precision']:.3f} | recall={m['recall']:.3f} | f1={m['f1']:.3f} | support={m['support']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern_ts_2E",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
