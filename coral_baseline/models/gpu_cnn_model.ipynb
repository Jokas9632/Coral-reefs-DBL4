{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74cc899d",
   "metadata": {},
   "source": [
    "### GPU Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb9eac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# Safer allocator settings (help fragmentation on Windows/WDDM)\n",
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = (\n",
    "    \"backend:cudaMallocAsync,\"\n",
    "    \"expandable_segments:True,\"\n",
    "    \"max_split_size_mb:64,\"\n",
    "    \"garbage_collection_threshold:0.8\"\n",
    ")\n",
    "\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd4ade4",
   "metadata": {},
   "source": [
    "### CNN Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3f0802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[masks] mapped 1517 indices from 2 file(s)\n",
      "[masks] mapped 166 indices from 1 file(s)\n",
      "[dataset] kept 1517/1517 indices (mask-covered).\n",
      "[dataset] kept 166/166 indices (mask-covered).\n",
      "[ready] train_cls len=1517 | val_cls len=166\n",
      "[loaders] train batches ≈ 48 | val batches ≈ 6\n",
      "[note] Loaders ready. Now run your model cell and training loop.\n"
     ]
    }
   ],
   "source": [
    "# === Recreate classification datasets + loaders (ONLY your Parquet files) ===\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from typing import Sequence, Optional, Callable, Union\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# ---- exact Parquet masks you provided ----\n",
    "TRAIN_PARQUETS = [\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part001.parquet\",\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part002.parquet\",\n",
    "]\n",
    "VAL_PARQUETS = [\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\validation\\validation_part001.parquet\",\n",
    "]\n",
    "MASK_COLUMN = \"label_health_rgb_png\"\n",
    "\n",
    "# ---- mask indexer: dataset index -> PNG ----\n",
    "class ParquetMasksByIndex:\n",
    "    def __init__(self, parquet_paths: Sequence[Union[str, Path]], column_png: str = MASK_COLUMN):\n",
    "        self._tables = [pq.read_table(Path(p)) for p in parquet_paths]\n",
    "        for t in self._tables:\n",
    "            if \"index\" not in t.column_names or column_png not in t.column_names:\n",
    "                raise ValueError(f\"Parquet must have 'index' and '{column_png}'. Got: {t.column_names}\")\n",
    "        self._col = column_png\n",
    "        self._map = {}\n",
    "        for tid, t in enumerate(self._tables):\n",
    "            for rid, ds_idx in enumerate(t[\"index\"].to_pylist()):\n",
    "                self._map[int(ds_idx)] = (tid, rid)\n",
    "        print(f\"[masks] mapped {len(self._map)} indices from {len(self._tables)} file(s)\")\n",
    "\n",
    "    def get_mask_pil(self, ds_index: int) -> Image.Image:\n",
    "        tid, rid = self._map[ds_index]\n",
    "        cell = self._tables[tid][self._col][rid].as_py()\n",
    "        if isinstance(cell, memoryview): cell = cell.tobytes()\n",
    "        elif isinstance(cell, bytearray): cell = bytes(cell)\n",
    "        return Image.open(BytesIO(cell)).convert(\"RGB\")\n",
    "\n",
    "# ---- HF images: EPFL-ECEO/coralscapes (train/validation) ----\n",
    "hf_all = load_dataset(\"EPFL-ECEO/coralscapes\")\n",
    "hf_train: HFDataset = hf_all[\"train\"]\n",
    "hf_val:   HFDataset = hf_all[\"validation\"]\n",
    "\n",
    "# ---- PIL -> tensor (copy() avoids \"non-writable\" warning) ----\n",
    "def pil_to_tensor_rgb(img: Image.Image) -> torch.Tensor:\n",
    "    arr = np.asarray(img.convert(\"RGB\"), dtype=np.uint8).copy()\n",
    "    return torch.from_numpy(arr).permute(2, 0, 1).float() / 255.0\n",
    "\n",
    "# ---- bind images (HF) + masks (your Parquets only), keep only covered indices ----\n",
    "class CoralScapesImagesMasks(Dataset):\n",
    "    def __init__(self, img_ds: HFDataset, masks: ParquetMasksByIndex,\n",
    "                 img_transform: Optional[Callable] = None,\n",
    "                 mask_transform: Optional[Callable] = None):\n",
    "        self.img_ds = img_ds\n",
    "        self.masks = masks\n",
    "        self.img_tf = img_transform\n",
    "        self.mask_tf = mask_transform\n",
    "        n = len(self.img_ds)\n",
    "        self.indices = [i for i in range(n) if i in masks._map]\n",
    "        print(f\"[dataset] kept {len(self.indices)}/{n} indices (mask-covered).\")\n",
    "\n",
    "    def __len__(self): return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, j: int):\n",
    "        idx = self.indices[j]\n",
    "        rec = self.img_ds[idx]\n",
    "        img = rec[\"image\"].convert(\"RGB\")\n",
    "        mask = self.masks.get_mask_pil(idx)\n",
    "        if self.img_tf is not None:  img  = self.img_tf(img)\n",
    "        if self.mask_tf is not None: mask = self.mask_tf(mask)\n",
    "        return img, mask\n",
    "\n",
    "masks_train = ParquetMasksByIndex(TRAIN_PARQUETS, MASK_COLUMN)\n",
    "masks_val   = ParquetMasksByIndex(VAL_PARQUETS,   MASK_COLUMN)\n",
    "cs_train = CoralScapesImagesMasks(hf_train, masks_train, pil_to_tensor_rgb, pil_to_tensor_rgb)\n",
    "cs_val   = CoralScapesImagesMasks(hf_val,   masks_val,   pil_to_tensor_rgb, pil_to_tensor_rgb)\n",
    "\n",
    "# ---- classification wrapper → (image_128x128, label) ----\n",
    "class MaskToBinaryLabel128(Dataset):\n",
    "    def __init__(self, base_ds: Dataset, size=128):\n",
    "        self.base = base_ds\n",
    "        self.size = size\n",
    "    def __len__(self): return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        img, mask = self.base[idx]  # tensors (3,H,W)\n",
    "        if img.shape[-2:] != (self.size, self.size):\n",
    "            img  = F.interpolate(img.unsqueeze(0),  size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "            mask = F.interpolate(mask.unsqueeze(0), size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        red  = mask[0].sum().item()\n",
    "        blue = mask[2].sum().item()\n",
    "        label = 1 if blue > red else 0  # bleached if blue energy > red\n",
    "        return img, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "train_cls = MaskToBinaryLabel128(cs_train, size=128)\n",
    "val_cls   = MaskToBinaryLabel128(cs_val,   size=128)\n",
    "\n",
    "print(f\"[ready] train_cls len={len(train_cls)} | val_cls len={len(val_cls)}\")\n",
    "\n",
    "# ---- loaders (GPU-friendly: pin_memory). If a global `model` exists, run a 1-batch smoke test.\n",
    "BATCH = 32  # if OOM: 16 → 8\n",
    "train_loader = DataLoader(train_cls, batch_size=BATCH, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_cls,   batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=True)\n",
    "print(f\"[loaders] train batches ≈ {len(train_loader)} | val batches ≈ {len(val_loader)}\")\n",
    "\n",
    "if 'model' in globals():\n",
    "    from torch.cuda.amp import autocast, GradScaler\n",
    "    DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
    "    xb, yb = next(iter(train_loader))\n",
    "    xb = xb.to(DEVICE, non_blocking=True); yb = yb.to(DEVICE, non_blocking=True)\n",
    "    with autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "        logits = model(xb); loss = criterion(logits, yb)\n",
    "    scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "    print(\"[smoke] 1 batch OK on\", DEVICE, \"| loss:\", float(loss))\n",
    "else:\n",
    "    print(\"[note] Loaders ready. Now run your model cell and training loop.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c4d07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda | NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "Model on: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\3707723666.py:38: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
      "c:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py:64: UserWarning: backend:cudaMallocAsync ignores max_split_size_mb,roundup_power2_divisions, and garbage_collect_threshold. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\cuda\\CUDAAllocatorConfig.cpp:322.)\n",
      "  return data.pin_memory(device)\n",
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\3707723666.py:43: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled=(DEVICE.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smoke batch OK | loss: 0.72027587890625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE, \"|\", torch.cuda.get_device_name(0) if DEVICE.type==\"cuda\" else \"\")\n",
    "torch.backends.cudnn.benchmark = True  # speed boost\n",
    "\n",
    "# Keras-like CNN (same conv stack you showed; GAP replaces giant Flatten)\n",
    "class KerasLikeCNN_GAP(nn.Module):\n",
    "    def __init__(self, p_drop=0.5):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=0),  # 128 -> 126\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),                 # 126 -> 63\n",
    "            nn.Conv2d(32, 64, 3, padding=0), # 63 -> 61\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 32, 1), nn.ReLU(inplace=True),  # Dense(32) over maps\n",
    "            nn.Conv2d(32, 64, 1), nn.ReLU(inplace=True),  # Dense(64) over maps\n",
    "            nn.Conv2d(64, 128, 3, padding=0), nn.ReLU(inplace=True),  # 61 -> 59\n",
    "            nn.Dropout(p=p_drop),\n",
    "            nn.AdaptiveAvgPool2d(1),         # replaces huge Flatten(59*59*128)\n",
    "        )\n",
    "        self.head = nn.Linear(128, 2)        # binary logits\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x).flatten(1)      # (B,128,1,1) -> (B,128)\n",
    "        return self.head(x)\n",
    "\n",
    "model = KerasLikeCNN_GAP(p_drop=0.5).to(DEVICE)\n",
    "print(\"Model on:\", next(model.parameters()).device)\n",
    "\n",
    "# Optim, loss, AMP scaler\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
    "\n",
    "# (optional) quick smoke test on one batch\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
    "with autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "    logits = model(xb); loss = criterion(logits, yb)\n",
    "scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "print(\"Smoke batch OK | loss:\", float(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a01a469",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\1664916854.py:20: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.set_grad_enabled(train), autocast(enabled=(DEVICE.type==\"cuda\")):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     36\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 37\u001b[0m     tr_loss, tr_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     va_loss, va_acc \u001b[38;5;241m=\u001b[39m run_epoch(val_loader,   train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     39\u001b[0m     dt \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m t0\n",
      "Cell \u001b[1;32mIn[7], line 16\u001b[0m, in \u001b[0;36mrun_epoch\u001b[1;34m(loader, train)\u001b[0m\n\u001b[0;32m     14\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     15\u001b[0m loss_sum \u001b[38;5;241m=\u001b[39m correct \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 16\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[2], line 90\u001b[0m, in \u001b[0;36mMaskToBinaryLabel128.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 90\u001b[0m     img, mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m  \u001b[38;5;66;03m# tensors (3,H,W)\u001b[39;00m\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize):\n\u001b[0;32m     92\u001b[0m         img  \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39minterpolate(img\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m),  size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbilinear\u001b[39m\u001b[38;5;124m\"\u001b[39m, align_corners\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 71\u001b[0m, in \u001b[0;36mCoralScapesImagesMasks.__getitem__\u001b[1;34m(self, j)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, j: \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m     70\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[j]\n\u001b[1;32m---> 71\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimg_ds\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     72\u001b[0m     img \u001b[38;5;241m=\u001b[39m rec[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     73\u001b[0m     mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmasks\u001b[38;5;241m.\u001b[39mget_mask_pil(idx)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\arrow_dataset.py:2862\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2860\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolars\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2861\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m-> 2862\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\arrow_dataset.py:2844\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2842\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2843\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m-> 2844\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[0;32m   2846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:658\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    656\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:411\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:460\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    459\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[1;32m--> 460\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:224\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\features.py:2097\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[1;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[0;32m   2082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[0;32m   2084\u001b[0m \n\u001b[0;32m   2085\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m-> 2097\u001b[0m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2098\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   2099\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m   2100\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[0;32m   2101\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[0;32m   2102\u001b[0m         )\n\u001b[0;32m   2103\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\features.py:1409\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[1;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m-> 1409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\image.py:193\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[1;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[1;32m--> 193\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\PIL\\ImageFile.py:390\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    389\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 390\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5, min_delta=1e-3):\n",
    "        self.patience = patience; self.min_delta = min_delta\n",
    "        self.best = float(\"inf\"); self.count = 0\n",
    "    def step(self, val_loss):\n",
    "        if self.best - val_loss > self.min_delta:\n",
    "            self.best = val_loss; self.count = 0; return False\n",
    "        self.count += 1; return self.count >= self.patience\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum = correct = n = 0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        if train: opt.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train), autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "        correct  += (logits.argmax(1) == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "    return loss_sum/max(1,n), correct/max(1,n)\n",
    "\n",
    "EPOCHS = 5\n",
    "early = EarlyStopper(patience=5, min_delta=1e-3)\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
    "    dt = time.time() - t0\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} - loss: {tr_loss:.4f} - acc: {tr_acc:.4f} \"\n",
    "          f\"- val_loss: {va_loss:.4f} - val_acc: {va_acc:.4f} - {dt:.1f}s\")\n",
    "    if best_state is None or va_loss < (early.best - 1e-3):\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    if early.step(va_loss):\n",
    "        print(f\"Epoch {epoch}: early stopping (best val_loss={early.best:.4f})\")\n",
    "        break\n",
    "\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best weights.\")\n",
    "\n",
    "# Final validation (like model.evaluate)\n",
    "model.eval()\n",
    "val_loss = val_acc = n = 0\n",
    "with torch.no_grad(), autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "    for xb, yb in val_loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        val_loss += loss.item() * xb.size(0)\n",
    "        val_acc  += (logits.argmax(1) == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "val_loss /= max(1, n)\n",
    "val_acc  /= max(1, n)\n",
    "print(\"Validation Loss:\", round(val_loss, 4))\n",
    "print(\"Validation Accuracy:\", round(val_acc, 4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0a170e",
   "metadata": {},
   "source": [
    "### with class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "482ad823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class counts -> healthy(0): 1339 | unhealthy(1): 178\n",
      "class weights: [0.5665, 4.2612]\n",
      "[loaders] train batches ≈ 48 | val batches ≈ 6\n"
     ]
    }
   ],
   "source": [
    "# === Per-class setup (0=healthy, 1=unhealthy/bleached) ===\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "\n",
    "CLASS_NAMES = {0: \"healthy\", 1: \"unhealthy\"}  # 1=bleached/unhealthy\n",
    "\n",
    "def label_from_mask_fast(mask_pil: Image.Image) -> int:\n",
    "    arr = np.asarray(mask_pil.convert(\"RGB\"), dtype=np.uint8)\n",
    "    red  = int(arr[..., 0].sum())\n",
    "    blue = int(arr[..., 2].sum())\n",
    "    return 1 if blue > red else 0  # unhealthy if blue dominates\n",
    "\n",
    "# Build labels aligned with train_cls order (no need to re-open images)\n",
    "train_labels = []\n",
    "for j in range(len(train_cls)):\n",
    "    idx = cs_train.indices[j]\n",
    "    m = masks_train.get_mask_pil(idx)\n",
    "    train_labels.append(label_from_mask_fast(m))\n",
    "\n",
    "cnt = Counter(train_labels)\n",
    "n0, n1 = cnt.get(0, 0), cnt.get(1, 0)\n",
    "print(f\"class counts -> healthy(0): {n0} | unhealthy(1): {n1}\")\n",
    "\n",
    "# Class weights inversely proportional to frequency\n",
    "total = len(train_labels)\n",
    "w0 = total / (2.0 * max(1, n0))\n",
    "w1 = total / (2.0 * max(1, n1))\n",
    "class_weights = torch.tensor([w0, w1], dtype=torch.float32, device=DEVICE)\n",
    "print(\"class weights:\", [round(float(w0), 4), round(float(w1), 4)])\n",
    "\n",
    "# Weighted sampler for balanced minibatches\n",
    "sample_weights = [w0 if y == 0 else w1 for y in train_labels]\n",
    "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
    "\n",
    "# Rebuild loaders (pin_memory for GPU IO). Keep val shuffled=False\n",
    "BATCH = 32  # drop to 16/8 if VRAM is tight\n",
    "train_loader = DataLoader(train_cls, batch_size=BATCH, sampler=sampler, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_cls,   batch_size=BATCH, shuffle=False,  num_workers=0, pin_memory=True)\n",
    "print(f\"[loaders] train batches ≈ {len(train_loader)} | val batches ≈ {len(val_loader)}\")\n",
    "\n",
    "# Re-define criterion with class weights (affects loss per class)\n",
    "import torch.nn as nn\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# (Optional) reset optimizer to start fresh with the new criterion\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74816316",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\3800905205.py:28: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.set_grad_enabled(train), autocast(enabled=(DEVICE.type==\"cuda\")):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/3 - loss: 0.3694 - acc: 0.4984 - val_loss: 0.9613 - val_acc: 0.2711 - 354.3s\n",
      "Epoch 02/3 - loss: 0.3717 - acc: 0.4937 - val_loss: 0.8740 - val_acc: 0.2711 - 316.0s\n",
      "Epoch 03/3 - loss: 0.3557 - acc: 0.5208 - val_loss: 1.0742 - val_acc: 0.2711 - 315.5s\n",
      "Loaded best weights.\n",
      "\n",
      "=== Validation (per class) ===\n",
      "Overall: loss=0.8739 | acc=0.2711\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "            pred: healthy   pred: unhealthy\n",
      "true healthy          0             121\n",
      "true unhealthy        0              45\n",
      "\n",
      "Per-class metrics:\n",
      "  healthy    | precision=0.000 | recall=0.000 | f1=0.000 | support=121\n",
      "  unhealthy  | precision=0.271 | recall=1.000 | f1=0.427 | support=45\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "# If you didn't define a scaler yet:\n",
    "try:\n",
    "    scaler\n",
    "except NameError:\n",
    "    scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=5, min_delta=1e-3):\n",
    "        self.patience = patience; self.min_delta = min_delta\n",
    "        self.best = float(\"inf\"); self.count = 0\n",
    "    def step(self, val_loss):\n",
    "        if self.best - val_loss > self.min_delta:\n",
    "            self.best = val_loss; self.count = 0; return False\n",
    "        self.count += 1; return self.count >= self.patience\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum = correct = n = 0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True)\n",
    "        yb = yb.to(DEVICE, non_blocking=True)\n",
    "        if train: opt.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train), autocast(enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt); scaler.update()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "        correct  += (logits.argmax(1) == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "    return loss_sum/max(1,n), correct/max(1,n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate_with_metrics(model, loader):\n",
    "    model.eval()\n",
    "    n = 0; loss_sum = 0\n",
    "    all_true = []; all_pred = []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "        logits = model(xb)\n",
    "        loss = criterion(logits, yb)\n",
    "        loss_sum += loss.item() * xb.size(0); n += xb.size(0)\n",
    "        all_true.append(yb.cpu()); all_pred.append(logits.argmax(1).cpu())\n",
    "    y_true = torch.cat(all_true)\n",
    "    y_pred = torch.cat(all_pred)\n",
    "    # Confusion matrix (2x2): rows=true, cols=pred\n",
    "    cm = torch.zeros(2, 2, dtype=torch.int64)\n",
    "    for t, p in zip(y_true, y_pred):\n",
    "        cm[t, p] += 1\n",
    "    # Per-class precision/recall/F1\n",
    "    per_class = {}\n",
    "    for c in [0, 1]:\n",
    "        tp = cm[c, c].item()\n",
    "        fp = cm[:, c].sum().item() - tp\n",
    "        fn = cm[c, :].sum().item() - tp\n",
    "        precision = tp / max(1, tp + fp)\n",
    "        recall    = tp / max(1, tp + fn)\n",
    "        f1        = 0.0 if (precision + recall) == 0 else 2 * precision * recall / (precision + recall)\n",
    "        per_class[c] = {\n",
    "            \"name\": CLASS_NAMES[c],\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1,\n",
    "            \"support\": cm[c, :].sum().item(),\n",
    "        }\n",
    "    acc = (y_true == y_pred).float().mean().item()\n",
    "    return {\"loss\": loss_sum/max(1,n), \"acc\": acc, \"cm\": cm, \"per_class\": per_class}\n",
    "\n",
    "# ---- Train with early stopping, save best by val loss ----\n",
    "EPOCHS = 3\n",
    "early = EarlyStopper(patience=5, min_delta=1e-3)\n",
    "best_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   train=False)\n",
    "    print(f\"Epoch {epoch:02d}/{EPOCHS} - loss: {tr_loss:.4f} - acc: {tr_acc:.4f} \"\n",
    "          f\"- val_loss: {va_loss:.4f} - val_acc: {va_acc:.4f} - {time.time()-t0:.1f}s\")\n",
    "    if best_state is None or va_loss < (early.best - 1e-3):\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    if early.step(va_loss):\n",
    "        print(f\"Epoch {epoch}: early stopping (best val_loss={early.best:.4f})\")\n",
    "        break\n",
    "\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best weights.\")\n",
    "\n",
    "# ---- Final evaluation with PER-CLASS metrics ----\n",
    "res = evaluate_with_metrics(model, val_loader)\n",
    "print(\"\\n=== Validation (per class) ===\")\n",
    "print(f\"Overall: loss={res['loss']:.4f} | acc={res['acc']:.4f}\")\n",
    "cm = res[\"cm\"].numpy()\n",
    "print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "print(f\"            pred: healthy   pred: unhealthy\")\n",
    "print(f\"true healthy     {cm[0,0]:>6}          {cm[0,1]:>6}\")\n",
    "print(f\"true unhealthy   {cm[1,0]:>6}          {cm[1,1]:>6}\")\n",
    "print(\"\\nPer-class metrics:\")\n",
    "for c in [0, 1]:\n",
    "    m = res[\"per_class\"][c]\n",
    "    print(f\"  {m['name']:<10} | precision={m['precision']:.3f} | recall={m['recall']:.3f} | f1={m['f1']:.3f} | support={m['support']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c76885c",
   "metadata": {},
   "source": [
    "### Test Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a18142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train label counts: Counter({0: 1339, 1: 178}) | val label counts: Counter({0: 121, 1: 45})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# 1) Build index lists the same way your datasets filtered them\n",
    "train_indices = [i for i in range(len(hf_train)) if i in masks_train._map]\n",
    "val_indices   = [i for i in range(len(hf_val))   if i in masks_val._map]\n",
    "\n",
    "def label_from_mask_bytes(mask_pil) -> int:\n",
    "    # unhealthy if blue channel energy > red channel energy\n",
    "    arr = np.asarray(mask_pil.convert(\"RGB\"), dtype=np.uint8)\n",
    "    return 1 if int(arr[...,2].sum()) > int(arr[...,0].sum()) else 0\n",
    "\n",
    "# 2) Precompute labels directly from original mask PNGs (no interpolation)\n",
    "y_train = []\n",
    "for idx in train_indices:\n",
    "    y_train.append(label_from_mask_bytes(masks_train.get_mask_pil(idx)))\n",
    "y_val = []\n",
    "for idx in val_indices:\n",
    "    y_val.append(label_from_mask_bytes(masks_val.get_mask_pil(idx)))\n",
    "\n",
    "cnt_tr = Counter(y_train); cnt_va = Counter(y_val)\n",
    "print(\"train label counts:\", cnt_tr, \"| val label counts:\", cnt_va)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66356cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ready] train=1517 | val=166\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "def pil_to_tensor_rgb(img):\n",
    "    arr = np.asarray(img.convert(\"RGB\"), dtype=np.uint8).copy()\n",
    "    return torch.from_numpy(arr).permute(2,0,1).float()/255.0\n",
    "\n",
    "class Images128WithLabels(Dataset):\n",
    "    def __init__(self, hf_ds, indices, labels, size=128):\n",
    "        assert len(indices) == len(labels)\n",
    "        self.hf = hf_ds\n",
    "        self.idx = list(indices)\n",
    "        self.y = torch.tensor(labels, dtype=torch.long)\n",
    "        self.size = size\n",
    "    def __len__(self): return len(self.idx)\n",
    "    def __getitem__(self, j):\n",
    "        i = self.idx[j]\n",
    "        img = self.hf[i][\"image\"]\n",
    "        x = pil_to_tensor_rgb(img)\n",
    "        if x.shape[-2:] != (self.size, self.size):\n",
    "            x = F.interpolate(x.unsqueeze(0), size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        return x, self.y[j]\n",
    "\n",
    "train_cls = Images128WithLabels(hf_train, train_indices, y_train, size=128)\n",
    "val_cls   = Images128WithLabels(hf_val,   val_indices,   y_val,   size=128)\n",
    "print(f\"[ready] train={len(train_cls)} | val={len(val_cls)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1c32f1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class balance train: 0→1339, 1→178 | sampler on\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# weights inversely proportional to class freq (on the precomputed labels)\n",
    "n = len(y_train); n0 = sum(1 for t in y_train if t==0); n1 = n - n0\n",
    "w0 = n/(2*max(1,n0)); w1 = n/(2*max(1,n1))\n",
    "weights = [w0 if t==0 else w1 for t in y_train]\n",
    "sampler = WeightedRandomSampler(weights, num_samples=len(weights), replacement=True)\n",
    "print(f\"class balance train: 0→{n0}, 1→{n1} | sampler on\")\n",
    "\n",
    "BATCH = 16  # 16/8 if VRAM is tight\n",
    "train_loader = DataLoader(train_cls, batch_size=BATCH, sampler=sampler, num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_cls,   batch_size=BATCH, shuffle=False,  num_workers=0, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19cdcdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cuda | NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\3758708072.py:39: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "smoke batch OK | loss: 2.2841014862060547\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using:\", DEVICE, \"|\", torch.cuda.get_device_name(0) if DEVICE.type==\"cuda\" else \"\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "class KerasLikeCNN_GAP(nn.Module):\n",
    "    def __init__(self, p_drop=0.3):  # slightly less dropout\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=0), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=0), nn.ReLU(True),\n",
    "            nn.Conv2d(64, 32, 1), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 1), nn.ReLU(True),\n",
    "            nn.Conv2d(64,128, 3, padding=0), nn.ReLU(True),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.head = nn.Linear(128, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x).flatten(1)\n",
    "        return self.head(x)\n",
    "\n",
    "model = KerasLikeCNN_GAP().to(DEVICE)\n",
    "\n",
    "# Bias warm-start to class prior so logits aren't skewed to class 1\n",
    "p1 = (n1 + 1e-6) / (n + 2e-6)        # prior for class 1\n",
    "prior_logit = np.log(p1/(1-p1))\n",
    "with torch.no_grad():\n",
    "    model.head.bias[:] = torch.tensor([ -prior_logit, prior_logit ], dtype=model.head.bias.dtype, device=DEVICE)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()     # ← no class weights now\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-4)  # slightly lower LR\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
    "\n",
    "# quick smoke test\n",
    "xb, yb = next(iter(train_loader))\n",
    "xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
    "with autocast(\"cuda\", enabled=(DEVICE.type==\"cuda\")):\n",
    "    logits = model(xb); loss = criterion(logits, yb)\n",
    "scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "print(\"smoke batch OK | loss:\", float(loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f24262f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/5 - loss:0.8971 - acc:0.5359 - val_loss:0.6334 - val_acc:0.6867 - 363.0s\n",
      "Epoch 02/5 - loss:0.6855 - acc:0.5583 - val_loss:0.6157 - val_acc:0.7229 - 314.3s\n",
      "Epoch 03/5 - loss:0.6792 - acc:0.5478 - val_loss:0.7407 - val_acc:0.3976 - 278.8s\n",
      "Epoch 04/5 - loss:0.6877 - acc:0.5603 - val_loss:0.6395 - val_acc:0.6747 - 309.7s\n",
      "Epoch 05/5 - loss:0.6955 - acc:0.5465 - val_loss:0.6547 - val_acc:0.6446 - 332.3s\n",
      "\n",
      "=== Validation (per class) ===\n",
      "Overall: loss=0.6157 | acc=0.7229\n",
      "\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "            pred: healthy   pred: unhealthy\n",
      "true healthy        120               1\n",
      "true unhealthy       45               0\n",
      "healthy    | precision=0.727 | recall=0.992 | f1=0.839 | support=121\n",
      "unhealthy  | precision=0.000 | recall=0.000 | f1=0.000 | support=45\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=6, min_delta=1e-3):\n",
    "        self.patience=patience; self.min_delta=min_delta\n",
    "        self.best=float(\"inf\"); self.count=0\n",
    "    def step(self, v):\n",
    "        if self.best - v > self.min_delta:\n",
    "            self.best=v; self.count=0; return False\n",
    "        self.count+=1; return self.count>=self.patience\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum=correct=n=0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
    "        if train: opt.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train), autocast(\"cuda\", enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "        correct  += (logits.argmax(1)==yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "    return loss_sum/max(1,n), correct/max(1,n)\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_per_class(loader):\n",
    "    model.eval()\n",
    "    y_true=[]; y_pred=[]\n",
    "    loss_sum=n=0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(DEVICE), yb.to(DEVICE)\n",
    "        with autocast(\"cuda\", enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb); loss = criterion(logits, yb)\n",
    "        loss_sum += loss.item()*xb.size(0); n += xb.size(0)\n",
    "        y_true.append(yb.cpu()); y_pred.append(logits.argmax(1).cpu())\n",
    "    y_true = torch.cat(y_true); y_pred=torch.cat(y_pred)\n",
    "    cm = torch.zeros(2,2, dtype=torch.int64)\n",
    "    for t,p in zip(y_true, y_pred): cm[t,p]+=1\n",
    "    def prf(c):\n",
    "        tp=cm[c,c].item(); fp=cm[:,c].sum().item()-tp; fn=cm[c,:].sum().item()-tp\n",
    "        prec = tp / max(1, tp+fp); rec = tp / max(1, tp+fn)\n",
    "        f1 = 0.0 if prec+rec==0 else 2*prec*rec/(prec+rec)\n",
    "        return prec, rec, f1, cm[c,:].sum().item()\n",
    "    p0,r0,f0,s0 = prf(0); p1,r1,f1,s1 = prf(1)\n",
    "    return {\n",
    "        \"loss\": loss_sum/max(1,n),\n",
    "        \"acc\": (y_true==y_pred).float().mean().item(),\n",
    "        \"cm\": cm,\n",
    "        \"per\": {0:{\"precision\":p0,\"recall\":r0,\"f1\":f0,\"support\":s0},\n",
    "                1:{\"precision\":p1,\"recall\":r1,\"f1\":f1,\"support\":s1}}\n",
    "    }\n",
    "\n",
    "EPOCHS = 5\n",
    "early = EarlyStopper(patience=6, min_delta=1e-3)\n",
    "best_state=None\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    t0=time.time()\n",
    "    tr_loss,tr_acc = run_epoch(train_loader, True)\n",
    "    va_loss,va_acc = run_epoch(val_loader,   False)\n",
    "    print(f\"Epoch {ep:02d}/{EPOCHS} - loss:{tr_loss:.4f} - acc:{tr_acc:.4f} \"\n",
    "          f\"- val_loss:{va_loss:.4f} - val_acc:{va_acc:.4f} - {time.time()-t0:.1f}s\")\n",
    "    if best_state is None or va_loss < (early.best-1e-3):\n",
    "        best_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "    if early.step(va_loss):\n",
    "        print(f\"Epoch {ep}: early stopping (best val_loss={early.best:.4f})\")\n",
    "        break\n",
    "\n",
    "if best_state: model.load_state_dict(best_state)\n",
    "\n",
    "# Final per-class report\n",
    "res = eval_per_class(val_loader)\n",
    "cm = res[\"cm\"].numpy()\n",
    "print(\"\\n=== Validation (per class) ===\")\n",
    "print(f\"Overall: loss={res['loss']:.4f} | acc={res['acc']:.4f}\")\n",
    "print(\"\\nConfusion Matrix (rows=true, cols=pred):\")\n",
    "print(f\"            pred: healthy   pred: unhealthy\")\n",
    "print(f\"true healthy     {cm[0,0]:>6}          {cm[0,1]:>6}\")\n",
    "print(f\"true unhealthy   {cm[1,0]:>6}          {cm[1,1]:>6}\")\n",
    "for c,name in {0:\"healthy\",1:\"unhealthy\"}.items():\n",
    "    m=res[\"per\"][c]\n",
    "    print(f\"{name:<10} | precision={m['precision']:.3f} | recall={m['recall']:.3f} | f1={m['f1']:.3f} | support={m['support']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e1e3aa",
   "metadata": {},
   "source": [
    "### Balanced Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e35007b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[labels] train counts → healthy(0)=1470 | unhealthy(1)=47\n",
      "[CB weights] alpha: [0.5470129251480103, 1.4529870748519897]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\217689652.py:55: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 90\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     89\u001b[0m     t0 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m---> 90\u001b[0m     tr_loss, tr_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     91\u001b[0m     va_loss, va_acc \u001b[38;5;241m=\u001b[39m run_epoch(val_loader,   \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     92\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - acc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - val_loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mva_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - val_acc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mva_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt0\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[33], line 71\u001b[0m, in \u001b[0;36mrun_epoch\u001b[1;34m(loader, train)\u001b[0m\n\u001b[0;32m     69\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     70\u001b[0m loss_sum \u001b[38;5;241m=\u001b[39m correct \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 71\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m;\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:350\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 108\u001b[0m, in \u001b[0;36mbuild_coralscapes_classification.<locals>.Images128WithLabels.__getitem__\u001b[1;34m(self, j)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, j):\n\u001b[0;32m    107\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx[j]\n\u001b[1;32m--> 108\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    109\u001b[0m     x \u001b[38;5;241m=\u001b[39m pil_to_tensor_rgb(img)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize):\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\arrow_dataset.py:2862\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2860\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolars\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2861\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m-> 2862\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\arrow_dataset.py:2844\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2842\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2843\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m-> 2844\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[0;32m   2846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:658\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    656\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:411\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:460\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    459\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[1;32m--> 460\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:224\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\features.py:2097\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[1;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[0;32m   2082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[0;32m   2084\u001b[0m \n\u001b[0;32m   2085\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m-> 2097\u001b[0m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2098\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   2099\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m   2100\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[0;32m   2101\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[0;32m   2102\u001b[0m         )\n\u001b[0;32m   2103\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\features.py:1409\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[1;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m-> 1409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\image.py:193\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[1;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[1;32m--> 193\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\PIL\\ImageFile.py:390\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    389\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 390\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- setup: CB-Focal loss + standard shuffled loader (no WeightedRandomSampler) ---\n",
    "import math, time, numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# 1) get training label counts (works with Images128WithLabels or any (x,y) dataset)\n",
    "def get_label_counts(ds):\n",
    "    if hasattr(ds, \"y\"):  # our Images128WithLabels exposes .y\n",
    "        y = ds.y.cpu().tolist()\n",
    "    else:\n",
    "        y = [int(ds[i][1]) for i in range(len(ds))]\n",
    "    n0 = sum(1 for t in y if t == 0); n1 = len(y) - n0\n",
    "    return n0, n1\n",
    "\n",
    "n0, n1 = get_label_counts(train_cls)\n",
    "print(f\"[labels] train counts → healthy(0)={n0} | unhealthy(1)={n1}\")\n",
    "\n",
    "# 2) Class-Balanced weights (effective number of samples, Cui et al.)\n",
    "def class_balanced_weights(n_per_class, beta=0.99):\n",
    "    w = []\n",
    "    for n in n_per_class:\n",
    "        n = max(1, n)\n",
    "        w_c = (1 - beta) / (1 - beta**n)\n",
    "        w.append(w_c)\n",
    "    # normalize so mean weight ≈ 1 (helps keep loss scale stable)\n",
    "    m = sum(w)/len(w)\n",
    "    return torch.tensor([wc/m for wc in w], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "cb_alpha = class_balanced_weights([n0, n1], beta=0.99)\n",
    "print(\"[CB weights] alpha:\", cb_alpha.tolist())\n",
    "\n",
    "# 3) Focal Cross-Entropy (multiclass) with class-balanced alpha\n",
    "def focal_ce_loss(logits, target, alpha=None, gamma=1.0):\n",
    "    # CE per-sample\n",
    "    ce = F.cross_entropy(logits, target, reduction=\"none\")\n",
    "    # p_t = prob of the true class\n",
    "    pt = F.softmax(logits, dim=1).gather(1, target.view(-1,1)).squeeze(1).clamp_(1e-6, 1-1e-6)\n",
    "    loss = ce * ((1 - pt) ** gamma)\n",
    "    if alpha is not None:\n",
    "        loss = loss * alpha[target]\n",
    "    return loss.mean()\n",
    "\n",
    "# 4) standard loaders (shuffle=True) — remove weighted sampler to avoid double-counting imbalance\n",
    "BATCH = 32  # drop to 16/8 if needed\n",
    "train_loader = DataLoader(train_cls, batch_size=BATCH, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_cls,   batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# 5) optimizer + AMP scaler (keep your existing model / GAP head)\n",
    "criterion = lambda logits, y: focal_ce_loss(logits, y, alpha=cb_alpha, gamma=1.0)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-4)   # slightly lower LR for stability\n",
    "scaler = GradScaler(enabled=(DEVICE.type == \"cuda\"))\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# 6) train with early stopping by val loss\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=6, min_delta=1e-3):\n",
    "        self.patience = patience; self.min_delta = min_delta\n",
    "        self.best = float(\"inf\"); self.count = 0\n",
    "    def step(self, v):\n",
    "        if self.best - v > self.min_delta:\n",
    "            self.best = v; self.count = 0; return False\n",
    "        self.count += 1; return self.count >= self.patience\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum = correct = n = 0\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE, non_blocking=True); yb = yb.to(DEVICE, non_blocking=True)\n",
    "        if train: opt.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train), autocast(\"cuda\", enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "        loss_sum += loss.item() * xb.size(0)\n",
    "        correct  += (logits.argmax(1) == yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "    return loss_sum/max(1,n), correct/max(1,n)\n",
    "\n",
    "EPOCHS = 6\n",
    "early = EarlyStopper(patience=6, min_delta=1e-3)\n",
    "best_state = None\n",
    "\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    t0 = time.time()\n",
    "    tr_loss, tr_acc = run_epoch(train_loader, True)\n",
    "    va_loss, va_acc = run_epoch(val_loader,   False)\n",
    "    print(f\"Epoch {ep:02d}/{EPOCHS} - loss:{tr_loss:.4f} - acc:{tr_acc:.4f} - val_loss:{va_loss:.4f} - val_acc:{va_acc:.4f} - {time.time()-t0:.1f}s\")\n",
    "    if best_state is None or va_loss < (early.best - 1e-3):\n",
    "        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}\n",
    "    if early.step(va_loss):\n",
    "        print(f\"Epoch {ep}: early stopping (best val_loss={early.best:.4f})\")\n",
    "        break\n",
    "\n",
    "if best_state: \n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best weights.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca191b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best threshold t=0.30 (by macro-F1=0.499)\n",
      "Overall: acc=0.518 | macro-F1=0.499\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "            pred: healthy   pred: unhealthy\n",
      "true healthy         59              62\n",
      "true unhealthy       18              27\n",
      "healthy   | precision=0.766 | recall=0.488 | f1=0.596\n",
      "unhealthy | precision=0.303 | recall=0.600 | f1=0.403\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_val_probs_and_labels(model, loader):\n",
    "    model.eval()\n",
    "    probs = []; labels = []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE); yb = yb.to(DEVICE)\n",
    "        with autocast(\"cuda\", enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            p = F.softmax(logits, dim=1)[:, 1]  # P(class=1 = unhealthy)\n",
    "        probs.append(p.cpu()); labels.append(yb.cpu())\n",
    "    return torch.cat(probs), torch.cat(labels)\n",
    "\n",
    "def metrics_from_preds(y_true, y_pred):\n",
    "    cm = torch.zeros(2,2, dtype=torch.int64)\n",
    "    for t,p in zip(y_true, y_pred): cm[t,p]+=1\n",
    "    def prf(c):\n",
    "        tp=cm[c,c].item(); fp=cm[:,c].sum().item()-tp; fn=cm[c,:].sum().item()-tp\n",
    "        prec = tp / max(1, tp+fp); rec = tp / max(1, tp+fn)\n",
    "        f1 = 0.0 if prec+rec==0 else 2*prec*rec/(prec+rec)\n",
    "        return prec, rec, f1\n",
    "    p0,r0,f0 = prf(0); p1,r1,f1 = prf(1)\n",
    "    macro_f1 = 0.5*(f0+f1)\n",
    "    acc = (y_true == y_pred).float().mean().item()\n",
    "    return {\"acc\":acc, \"macro_f1\":macro_f1, \"cm\":cm, \"per\":{\"healthy\":(p0,r0,f0),\"unhealthy\":(p1,r1,f1)}}\n",
    "\n",
    "# 1) collect probabilities for class=1 on the val set\n",
    "probs, y_true = collect_val_probs_and_labels(model, val_loader)\n",
    "\n",
    "# 2) sweep thresholds and pick the one that maximizes macro-F1 (balanced performance)\n",
    "best = {\"t\":0.5, \"macro_f1\":-1}\n",
    "for t in torch.linspace(0.1, 0.9, steps=17):  # 0.1 → 0.9 step 0.05\n",
    "    y_pred = (probs >= t).long()\n",
    "    m = metrics_from_preds(y_true, y_pred)\n",
    "    if m[\"macro_f1\"] > best[\"macro_f1\"]:\n",
    "        best = {\"t\": float(t), \"macro_f1\": m[\"macro_f1\"], \"metrics\": m}\n",
    "\n",
    "m = best[\"metrics\"]; cm = m[\"cm\"].numpy()\n",
    "(p0,r0,f0) = m[\"per\"][\"healthy\"]; (p1,r1,f1) = m[\"per\"][\"unhealthy\"]\n",
    "print(f\"\\nBest threshold t={best['t']:.2f} (by macro-F1={best['macro_f1']:.3f})\")\n",
    "print(f\"Overall: acc={m['acc']:.3f} | macro-F1={m['macro_f1']:.3f}\")\n",
    "print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "#print(f\"            pred: healthy   pred: unhealthy\")\n",
    "#print(f\"true healthy     {cm[0,0]:>6}          {cm[0,1]:>6}\")\n",
    "#print(f\"true unhealthy   {cm[1,0]:>6}          {cm[1,1]:>6}\")\n",
    "print(f\"healthy   | precision={p0:.3f} | recall={r0:.3f} | f1={f0:.3f}\")\n",
    "print(f\"unhealthy | precision={p1:.3f} | recall={r1:.3f} | f1={f1:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d749119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TEST @ val-tuned threshold ===\n",
      "threshold t=0.0100 | acc=0.9031 | macro-F1=0.4745\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "            pred: healthy   pred: unhealthy\n",
      "true healthy        354               0\n",
      "true unhealthy       38               0\n",
      "healthy   | precision=0.903 | recall=1.000 | f1=0.949\n",
      "unhealthy | precision=0.000 | recall=0.000 | f1=0.000\n",
      "\n",
      "=== TEST @ best macro-F1 (diagnostic) ===\n",
      "threshold t=0.0025 | acc=0.9031 | macro-F1=0.4745\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "            pred: healthy   pred: unhealthy\n",
      "true healthy        354               0\n",
      "true unhealthy       38               0\n",
      "healthy   | precision=0.903 | recall=1.000 | f1=0.949\n",
      "unhealthy | precision=0.000 | recall=0.000 | f1=0.000\n",
      "\n",
      "=== TEST @ prevalence-matched threshold ===\n",
      "threshold t=0.0012 | acc=0.6097 | macro-F1=0.5206\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "            pred: healthy   pred: unhealthy\n",
      "true healthy        204             150\n",
      "true unhealthy        3              35\n",
      "healthy   | precision=0.986 | recall=0.576 | f1=0.727\n",
      "unhealthy | precision=0.189 | recall=0.921 | f1=0.314\n"
     ]
    }
   ],
   "source": [
    "# ========= Balanced decision rules for TEST =========\n",
    "import torch\n",
    "from torch.amp import autocast\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_probs_and_labels(model, loader, device):\n",
    "    model.eval()\n",
    "    probs = []; labels = []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device); yb = yb.to(device)\n",
    "        with autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            p = torch.softmax(logits, dim=1)[:, 1]  # P(unhealthy)\n",
    "        probs.append(p.cpu()); labels.append(yb.cpu())\n",
    "    return torch.cat(probs), torch.cat(labels)\n",
    "\n",
    "def metrics_from_preds(y_true, y_pred):\n",
    "    cm = torch.zeros(2,2, dtype=torch.int64)\n",
    "    for t,p in zip(y_true, y_pred): cm[t,p]+=1\n",
    "    def prf(c):\n",
    "        tp=cm[c,c].item(); fp=cm[:,c].sum().item()-tp; fn=cm[c,:].sum().item()-tp\n",
    "        prec = tp / max(1, tp+fp); rec = tp / max(1, tp+fn)\n",
    "        f1 = 0.0 if prec+rec==0 else 2*prec*rec/(prec+rec)\n",
    "        return prec, rec, f1\n",
    "    p0,r0,f0 = prf(0); p1,r1,f1 = prf(1)\n",
    "    macro_f1 = 0.5*(f0+f1)\n",
    "    acc = (y_true == y_pred).float().mean().item()\n",
    "    return {\"acc\":acc, \"macro_f1\":macro_f1, \"cm\":cm, \"per\":{\"healthy\":(p0,r0,f0),\"unhealthy\":(p1,r1,f1)}}\n",
    "\n",
    "def report(name, probs, y_true, t):\n",
    "    y_pred = (probs >= t).long()\n",
    "    m = metrics_from_preds(y_true, y_pred)\n",
    "    cm = m[\"cm\"].numpy()\n",
    "    (p0,r0,f0) = m[\"per\"][\"healthy\"]; (p1,r1,f1) = m[\"per\"][\"unhealthy\"]\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"threshold t={t:.4f} | acc={m['acc']:.4f} | macro-F1={m['macro_f1']:.4f}\")\n",
    "    print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "    print(f\"            pred: healthy   pred: unhealthy\")\n",
    "    print(f\"true healthy     {cm[0,0]:>6}          {cm[0,1]:>6}\")\n",
    "    print(f\"true unhealthy   {cm[1,0]:>6}          {cm[1,1]:>6}\")\n",
    "    print(f\"healthy   | precision={p0:.3f} | recall={r0:.3f} | f1={f0:.3f}\")\n",
    "    print(f\"unhealthy | precision={p1:.3f} | recall={r1:.3f} | f1={f1:.3f}\")\n",
    "    return m\n",
    "\n",
    "# 1) Collect VAL/TEST probs\n",
    "probs_val, y_val_true   = collect_probs_and_labels(model, val_loader,  DEVICE)\n",
    "probs_test, y_test_true = collect_probs_and_labels(model, test_loader, DEVICE)\n",
    "\n",
    "# 2) Best threshold on VAL by macro-F1 (your current approach)\n",
    "best_val = {\"t\": 0.5, \"macro_f1\": -1}\n",
    "for t in torch.linspace(0.01, 0.99, steps=199):  # wider sweep; catches low-prob regimes\n",
    "    m = metrics_from_preds(y_val_true, (probs_val >= t).long())\n",
    "    if m[\"macro_f1\"] > best_val[\"macro_f1\"]:\n",
    "        best_val = {\"t\": float(t), \"macro_f1\": m[\"macro_f1\"], \"metrics\": m}\n",
    "t_val = best_val[\"t\"]\n",
    "report(\"TEST @ val-tuned threshold\", probs_test, y_test_true, t_val)\n",
    "\n",
    "# 3) (Analysis) Best macro-F1 directly on TEST (diagnostic view)\n",
    "best_test = {\"t\": 0.5, \"macro_f1\": -1}\n",
    "for t in torch.linspace(0.0, 1.0, steps=401):\n",
    "    m = metrics_from_preds(y_test_true, (probs_test >= t).long())\n",
    "    if m[\"macro_f1\"] > best_test[\"macro_f1\"]:\n",
    "        best_test = {\"t\": float(t), \"macro_f1\": m[\"macro_f1\"], \"metrics\": m}\n",
    "t_test_best = best_test[\"t\"]\n",
    "report(\"TEST @ best macro-F1 (diagnostic)\", probs_test, y_test_true, t_test_best)\n",
    "\n",
    "# 4) Prevalence-matched threshold on TEST: predict ~same # of \"unhealthy\" as ground truth\n",
    "pos = int((y_test_true == 1).sum().item())\n",
    "N   = len(y_test_true)\n",
    "if 0 < pos < N:\n",
    "    s, _ = torch.sort(probs_test, descending=True)\n",
    "    # pick midpoint between the k-th and (k+1)-th largest scores to get exactly 'pos' positives\n",
    "    k = pos\n",
    "    if k < N:\n",
    "        t_prev = float((s[k-1] + s[k]) / 2.0)  # midpoint\n",
    "    else:\n",
    "        t_prev = float(s[-1].item() - 1e-8)    # degenerate case\n",
    "    report(\"TEST @ prevalence-matched threshold\", probs_test, y_test_true, t_prev)\n",
    "else:\n",
    "    print(\"[warn] test set has 0 or N positives; skipping prevalence-matched threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "535b33f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== VAL @ equal-recall threshold ===\n",
      "threshold t=0.0020 | acc=0.9217 | macro-F1=0.4796\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "            pred: healthy   pred: unhealthy\n",
      "true healthy        153               0\n",
      "true unhealthy       13               0\n",
      "healthy   | precision=0.922 | recall=1.000 | f1=0.959\n",
      "unhealthy | precision=0.000 | recall=0.000 | f1=0.000\n",
      "\n",
      "=== TEST @ equal-recall threshold (val-tuned) ===\n",
      "threshold t=0.0020 | acc=0.9031 | macro-F1=0.4745\n",
      "Confusion Matrix (rows=true, cols=pred):\n",
      "            pred: healthy   pred: unhealthy\n",
      "true healthy        354               0\n",
      "true unhealthy       38               0\n",
      "healthy   | precision=0.903 | recall=1.000 | f1=0.949\n",
      "unhealthy | precision=0.000 | recall=0.000 | f1=0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'acc': 0.9030612111091614,\n",
       " 'macro_f1': 0.47453083109919575,\n",
       " 'cm': tensor([[354,   0],\n",
       "         [ 38,   0]]),\n",
       " 'per': {'healthy': (0.9030612244897959, 1.0, 0.9490616621983915),\n",
       "  'unhealthy': (0.0, 0.0, 0.0)}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.amp import autocast\n",
    "\n",
    "@torch.no_grad()\n",
    "def collect_probs_and_labels(model, loader, device):\n",
    "    model.eval()\n",
    "    probs = []; labels = []\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device); yb = yb.to(device)\n",
    "        with autocast(\"cuda\", enabled=(device.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            p = torch.softmax(logits, dim=1)[:, 1]  # P(unhealthy)\n",
    "        probs.append(p.cpu()); labels.append(yb.cpu())\n",
    "    return torch.cat(probs), torch.cat(labels)\n",
    "\n",
    "def metrics_from_preds(y_true, y_pred):\n",
    "    cm = torch.zeros(2,2, dtype=torch.int64)\n",
    "    for t,p in zip(y_true, y_pred): cm[t,p]+=1\n",
    "    def prf(c):\n",
    "        tp=cm[c,c].item(); fp=cm[:,c].sum().item()-tp; fn=cm[c,:].sum().item()-tp\n",
    "        prec = tp / max(1, tp+fp); rec = tp / max(1, tp+fn)\n",
    "        f1 = 0.0 if prec+rec==0 else 2*prec*rec/(prec+rec)\n",
    "        return prec, rec, f1\n",
    "    p0,r0,f0 = prf(0); p1,r1,f1 = prf(1)\n",
    "    macro_f1 = 0.5*(f0+f1)\n",
    "    acc = (y_true == y_pred).float().mean().item()\n",
    "    return {\"acc\":acc, \"macro_f1\":macro_f1, \"cm\":cm,\n",
    "            \"per\":{\"healthy\":(p0,r0,f0),\"unhealthy\":(p1,r1,f1)}}\n",
    "\n",
    "def report(name, probs, y_true, t):\n",
    "    y_pred = (probs >= t).long()\n",
    "    m = metrics_from_preds(y_true, y_pred)\n",
    "    cm = m[\"cm\"].numpy()\n",
    "    (p0,r0,f0) = m[\"per\"][\"healthy\"]; (p1,r1,f1) = m[\"per\"][\"unhealthy\"]\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(f\"threshold t={t:.4f} | acc={m['acc']:.4f} | macro-F1={m['macro_f1']:.4f}\")\n",
    "    print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "    print(f\"            pred: healthy   pred: unhealthy\")\n",
    "    print(f\"true healthy     {cm[0,0]:>6}          {cm[0,1]:>6}\")\n",
    "    print(f\"true unhealthy   {cm[1,0]:>6}          {cm[1,1]:>6}\")\n",
    "    print(f\"healthy   | precision={p0:.3f} | recall={r0:.3f} | f1={f0:.3f}\")\n",
    "    print(f\"unhealthy | precision={p1:.3f} | recall={r1:.3f} | f1={f1:.3f}\")\n",
    "    return m\n",
    "\n",
    "# 1) collect val/test probabilities\n",
    "probs_val, y_val = collect_probs_and_labels(model, val_loader,  DEVICE)\n",
    "probs_tst, y_tst = collect_probs_and_labels(model, test_loader, DEVICE)\n",
    "\n",
    "# 2) choose threshold on VAL to minimize |recall_healthy - recall_unhealthy|,\n",
    "#    tie-break by highest macro-F1, then by highest unhealthy recall.\n",
    "best = None\n",
    "grid = torch.linspace(0.0, 1.0, steps=1001)\n",
    "for t in grid:\n",
    "    m = metrics_from_preds(y_val, (probs_val >= t).long())\n",
    "    _, r0, _ = m[\"per\"][\"healthy\"]\n",
    "    _, r1, _ = m[\"per\"][\"unhealthy\"]\n",
    "    gap = abs(r0 - r1)\n",
    "    score = ( -gap, m[\"macro_f1\"], r1 )  # lexicographic: smallest gap, then best macro-F1, then higher r1\n",
    "    if (best is None) or (score > best[\"score\"]):\n",
    "        best = {\"t\": float(t), \"score\": score, \"metrics\": m}\n",
    "\n",
    "t_eqrec = best[\"t\"]\n",
    "report(\"VAL @ equal-recall threshold\", probs_val, y_val, t_eqrec)\n",
    "\n",
    "# 3) apply that threshold on TEST\n",
    "report(\"TEST @ equal-recall threshold (val-tuned)\", probs_tst, y_tst, t_eqrec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f2433",
   "metadata": {},
   "source": [
    "### Finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5699cf39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda | NVIDIA GeForce RTX 3050 Ti Laptop GPU\n",
      "[CS masks] mapped 1517 indices from 2 file(s)\n",
      "[CS masks] mapped 166 indices from 1 file(s)\n",
      "[benthic] using 0 wrapped datasets: []\n",
      "[combined] train=1517 | val=166\n",
      "[labels] train counts → healthy(0)=1470 | unhealthy(1)=47\n",
      "[CB weights] alpha: [0.5470129251480103, 1.4529870748519897]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sedya\\AppData\\Local\\Temp\\ipykernel_30000\\1876685006.py:315: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 349\u001b[0m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    348\u001b[0m     t0\u001b[38;5;241m=\u001b[39mtime\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 349\u001b[0m     tr_loss,tr_acc \u001b[38;5;241m=\u001b[39m \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    350\u001b[0m     va_loss,va_acc \u001b[38;5;241m=\u001b[39m run_epoch(val_loader,   \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    351\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mep\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - acc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - val_loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mva_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - val_acc:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mva_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mt0\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[25], line 331\u001b[0m, in \u001b[0;36mrun_epoch\u001b[1;34m(loader, train)\u001b[0m\n\u001b[0;32m    329\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain() \u001b[38;5;28;01mif\u001b[39;00m train \u001b[38;5;28;01melse\u001b[39;00m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m    330\u001b[0m loss_sum\u001b[38;5;241m=\u001b[39mcorrect\u001b[38;5;241m=\u001b[39mn\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 331\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mxb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    707\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:350\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    348\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    349\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 108\u001b[0m, in \u001b[0;36mbuild_coralscapes_classification.<locals>.Images128WithLabels.__getitem__\u001b[1;34m(self, j)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, j):\n\u001b[0;32m    107\u001b[0m     i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midx[j]\n\u001b[1;32m--> 108\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    109\u001b[0m     x \u001b[38;5;241m=\u001b[39m pil_to_tensor_rgb(img)\n\u001b[0;32m    110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:] \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize):\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\arrow_dataset.py:2862\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2860\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marrow\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpolars\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2861\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[1;32m-> 2862\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\arrow_dataset.py:2844\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2842\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[0;32m   2843\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[1;32m-> 2844\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2845\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[0;32m   2846\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2847\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:658\u001b[0m, in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    656\u001b[0m python_formatter \u001b[38;5;241m=\u001b[39m PythonFormatter(features\u001b[38;5;241m=\u001b[39mformatter\u001b[38;5;241m.\u001b[39mfeatures)\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 658\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    660\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:411\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 411\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    412\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    413\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:460\u001b[0m, in \u001b[0;36mPythonFormatter.format_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m LazyRow(pa_table, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    459\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[1;32m--> 460\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpython_features_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\formatting\\formatting.py:224\u001b[0m, in \u001b[0;36mPythonFeaturesDecoder.decode_row\u001b[1;34m(self, row)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_row\u001b[39m(\u001b[38;5;28mself\u001b[39m, row: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m--> 224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;28;01melse\u001b[39;00m row\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\features.py:2097\u001b[0m, in \u001b[0;36mFeatures.decode_example\u001b[1;34m(self, example, token_per_repo_id)\u001b[0m\n\u001b[0;32m   2082\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode_example\u001b[39m(\u001b[38;5;28mself\u001b[39m, example: \u001b[38;5;28mdict\u001b[39m, token_per_repo_id: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2083\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Decode example with custom feature decoding.\u001b[39;00m\n\u001b[0;32m   2084\u001b[0m \n\u001b[0;32m   2085\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2093\u001b[0m \u001b[38;5;124;03m        `dict[str, Any]`\u001b[39;00m\n\u001b[0;32m   2094\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   2096\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m-> 2097\u001b[0m         column_name: \u001b[43mdecode_nested_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2098\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_requires_decoding[column_name]\n\u001b[0;32m   2099\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[0;32m   2100\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m column_name, (feature, value) \u001b[38;5;129;01min\u001b[39;00m zip_dict(\n\u001b[0;32m   2101\u001b[0m             {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m example}, example\n\u001b[0;32m   2102\u001b[0m         )\n\u001b[0;32m   2103\u001b[0m     }\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\features.py:1409\u001b[0m, in \u001b[0;36mdecode_nested_example\u001b[1;34m(schema, obj, token_per_repo_id)\u001b[0m\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;66;03m# Object with special decoding:\u001b[39;00m\n\u001b[0;32m   1407\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode_example\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(schema, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m   1408\u001b[0m     \u001b[38;5;66;03m# we pass the token to read and decode files from private repositories in streaming mode\u001b[39;00m\n\u001b[1;32m-> 1409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mschema\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_per_repo_id\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\datasets\\features\\image.py:193\u001b[0m, in \u001b[0;36mImage.decode_example\u001b[1;34m(self, value, token_per_repo_id)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(BytesIO(bytes_))\n\u001b[1;32m--> 193\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# to avoid \"Too many open files\" errors\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m image\u001b[38;5;241m.\u001b[39mgetexif()\u001b[38;5;241m.\u001b[39mget(PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mExifTags\u001b[38;5;241m.\u001b[39mBase\u001b[38;5;241m.\u001b[39mOrientation) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     image \u001b[38;5;241m=\u001b[39m PIL\u001b[38;5;241m.\u001b[39mImageOps\u001b[38;5;241m.\u001b[39mexif_transpose(image)\n",
      "File \u001b[1;32mc:\\Users\\sedya\\anaconda2024\\envs\\modern_ts_2E\\Lib\\site-packages\\PIL\\ImageFile.py:390\u001b[0m, in \u001b[0;36mImageFile.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[0;32m    389\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[1;32m--> 390\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Combine CoralScapes + CoralBleaching + Benthic for classification (128x128)\n",
    "# Balanced training with Class-Balanced Focal Loss + threshold tuning\n",
    "# ============================================================\n",
    "import os, math, time\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from typing import Sequence, Optional, Callable, Union, List, Tuple\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset, Subset\n",
    "from torch.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "import pyarrow.parquet as pq\n",
    "from datasets import load_dataset, Dataset as HFDataset\n",
    "\n",
    "# ---------------- GPU setup (Windows/WDDM fragmentation guard) ----------------\n",
    "os.environ.setdefault(\"PYTORCH_CUDA_ALLOC_CONF\",\n",
    "    \"backend:cudaMallocAsync,expandable_segments:True,max_split_size_mb:64,garbage_collection_threshold:0.8\")\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", DEVICE, \"|\", torch.cuda.get_device_name(0) if DEVICE.type==\"cuda\" else \"\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# ---------------- Common utilities ----------------\n",
    "def pil_to_tensor_rgb(img: Image.Image) -> torch.Tensor:\n",
    "    arr = np.asarray(img.convert(\"RGB\"), dtype=np.uint8).copy()\n",
    "    return torch.from_numpy(arr).permute(2,0,1).float()/255.0\n",
    "\n",
    "def label_from_mask_pil(mask_pil: Image.Image) -> int:\n",
    "    # 0=healthy, 1=unhealthy (bleached), by blue-vs-red energy\n",
    "    arr = np.asarray(mask_pil.convert(\"RGB\"), dtype=np.uint8)\n",
    "    return 1 if int(arr[...,2].sum()) > int(arr[...,0].sum()) else 0\n",
    "\n",
    "def label_from_mask_tensor(mask_t: torch.Tensor, min_ratio: float = 1.05, min_signal: float = 0.01):\n",
    "    \"\"\"\n",
    "    For benthic (tensor masks). Returns 0/1 or None if ambiguous.\n",
    "    - min_ratio: require clear dominance of blue vs red (or red vs blue)\n",
    "    - min_signal: require enough red/blue energy to be meaningful\n",
    "    \"\"\"\n",
    "    # mask_t is (3,H,W) in [0,1]\n",
    "    red  = float(mask_t[0].sum().item())\n",
    "    blue = float(mask_t[2].sum().item())\n",
    "    tot  = float(mask_t.sum().item()) + 1e-8\n",
    "    # discard if too little colored signal\n",
    "    if (red + blue) / tot < min_signal:\n",
    "        return None\n",
    "    # dominance check\n",
    "    if blue > red * min_ratio:  # blue dominates => unhealthy\n",
    "        return 1\n",
    "    if red > blue * min_ratio:  # red dominates => healthy\n",
    "        return 0\n",
    "    return None  # ambiguous\n",
    "\n",
    "# ---------------- CoralScapes (HF images) + your Parquet masks → classification ----------------\n",
    "TRAIN_PARQUETS = [\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part001.parquet\",\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\train\\train_part002.parquet\",\n",
    "]\n",
    "VAL_PARQUETS = [\n",
    "    r\"C:\\Users\\sedya\\VScodeProjects\\Coral-reefs-DBL4\\data_preprocessing\\coralscapes_export\\parquet\\validation\\validation_part001.parquet\",\n",
    "]\n",
    "MASK_COLUMN = \"label_health_rgb_png\"\n",
    "\n",
    "class ParquetMasksByIndex:\n",
    "    def __init__(self, parquet_paths: Sequence[Union[str, Path]], col_png: str = MASK_COLUMN):\n",
    "        self._tables = [pq.read_table(Path(p)) for p in parquet_paths]\n",
    "        for t in self._tables:\n",
    "            if \"index\" not in t.column_names or col_png not in t.column_names:\n",
    "                raise ValueError(f\"Parquet must have 'index' and '{col_png}'. Got: {t.column_names}\")\n",
    "        self._col = col_png\n",
    "        self._map = {}\n",
    "        for tid, t in enumerate(self._tables):\n",
    "            for rid, ds_idx in enumerate(t[\"index\"].to_pylist()):\n",
    "                self._map[int(ds_idx)] = (tid, rid)\n",
    "        print(f\"[CS masks] mapped {len(self._map)} indices from {len(self._tables)} file(s)\")\n",
    "\n",
    "    def get_mask_pil(self, ds_index: int) -> Image.Image:\n",
    "        tid, rid = self._map[ds_index]\n",
    "        cell = self._tables[tid][self._col][rid].as_py()\n",
    "        if isinstance(cell, memoryview): cell = cell.tobytes()\n",
    "        elif isinstance(cell, bytearray): cell = bytes(cell)\n",
    "        return Image.open(BytesIO(cell)).convert(\"RGB\")\n",
    "\n",
    "def build_coralscapes_classification(size: int = 128):\n",
    "    hf = load_dataset(\"EPFL-ECEO/coralscapes\")\n",
    "    hf_train, hf_val = hf[\"train\"], hf[\"validation\"]\n",
    "    masks_train = ParquetMasksByIndex(TRAIN_PARQUETS, MASK_COLUMN)\n",
    "    masks_val   = ParquetMasksByIndex(VAL_PARQUETS,   MASK_COLUMN)\n",
    "\n",
    "    idx_train = [i for i in range(len(hf_train)) if i in masks_train._map]\n",
    "    idx_val   = [i for i in range(len(hf_val))   if i in masks_val._map]\n",
    "    y_train   = [label_from_mask_pil(masks_train.get_mask_pil(i)) for i in idx_train]\n",
    "    y_val     = [label_from_mask_pil(masks_val.get_mask_pil(i))   for i in idx_val]\n",
    "\n",
    "    class Images128WithLabels(Dataset):\n",
    "        def __init__(self, hf_ds: HFDataset, indices: List[int], labels: List[int], size=128):\n",
    "            assert len(indices)==len(labels)\n",
    "            self.hf, self.idx = hf_ds, list(indices)\n",
    "            self.y = torch.tensor(labels, dtype=torch.long)\n",
    "            self.size = size\n",
    "        def __len__(self): return len(self.idx)\n",
    "        def __getitem__(self, j):\n",
    "            i = self.idx[j]\n",
    "            img = self.hf[i][\"image\"]\n",
    "            x = pil_to_tensor_rgb(img)\n",
    "            if x.shape[-2:] != (self.size, self.size):\n",
    "                x = F.interpolate(x.unsqueeze(0), size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "            return x, self.y[j]\n",
    "\n",
    "    ds_tr = Images128WithLabels(hf_train, idx_train, y_train, size)\n",
    "    ds_va = Images128WithLabels(hf_val,   idx_val,   y_val,   size)\n",
    "    return ds_tr, ds_va\n",
    "\n",
    "# ---------------- Coral Bleaching local → classification ----------------\n",
    "BLEACH_IMAGES  = r\"g:\\.shortcut-targets-by-id\\1jGkNA1n0znoxKnQBHTJZuPgvkiu_OBM8\\coral_bleaching\\reef_support\\UNAL_BLEACHING_TAYRONA\\images\"\n",
    "BLEACH_COMBINED = r\"data_preprocessing/coralbleaching/combined_masks\"\n",
    "BLEACH_SINGLE   = r\"data_preprocessing/coralbleaching/single_masks\"\n",
    "\n",
    "class CoralBleachingPairs(Dataset):\n",
    "    def __init__(self, images_dir: Union[str, Path], combined_dir: Union[str, Path], single_dir: Union[str, Path]):\n",
    "        self.images_dir = Path(images_dir)\n",
    "        self.combined_dir = Path(combined_dir)\n",
    "        self.single_bleached = Path(single_dir) / \"bleached_blue\"\n",
    "        self.single_non = Path(single_dir) / \"non_bleached_red\"\n",
    "        imgs = []\n",
    "        for e in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.bmp\",\"*.tif\",\"*.tiff\"):\n",
    "            imgs += list(self.images_dir.glob(e))\n",
    "        self.images = sorted(imgs)\n",
    "        self.pairs = self._match_pairs()\n",
    "\n",
    "    def _index_dir(self, d: Path) -> dict:\n",
    "        out = {}\n",
    "        for e in (\"*.png\",\"*.jpg\",\"*.jpeg\",\"*.bmp\",\"*.tif\",\"*.tiff\"):\n",
    "            for p in d.glob(e): out[p.stem.lower()] = p\n",
    "        return out\n",
    "\n",
    "    def _match_pairs(self) -> List[Tuple[Path, Path]]:\n",
    "        cmb = self._index_dir(self.combined_dir)\n",
    "        ble = self._index_dir(self.single_bleached)\n",
    "        non = self._index_dir(self.single_non)\n",
    "        pairs=[]\n",
    "        for img in self.images:\n",
    "            key = img.stem.lower()\n",
    "            k_cmb = f\"{key}_combined\"\n",
    "            if k_cmb in cmb:\n",
    "                pairs.append((img, cmb[k_cmb])); continue\n",
    "            cand = [p for k,p in ble.items() if k.startswith(key) or key in k]\n",
    "            if cand: pairs.append((img, cand[0])); continue\n",
    "            cand = [p for k,p in non.items() if k.startswith(key) or key in k]\n",
    "            if cand: pairs.append((img, cand[0]))\n",
    "        return pairs\n",
    "\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, i):\n",
    "        ip, mp = self.pairs[i]\n",
    "        return Image.open(ip).convert(\"RGB\"), Image.open(mp).convert(\"RGB\")\n",
    "\n",
    "class PairToImages128WithLabels(Dataset):\n",
    "    def __init__(self, base_pairs: Dataset, size=128):\n",
    "        self.base = base_pairs\n",
    "        self.size = size\n",
    "    def __len__(self): return len(self.base)\n",
    "    def __getitem__(self, idx):\n",
    "        img_pil, mask_pil = self.base[idx]\n",
    "        y = label_from_mask_pil(mask_pil)\n",
    "        x = pil_to_tensor_rgb(img_pil)\n",
    "        if x.shape[-2:] != (self.size, self.size):\n",
    "            x = F.interpolate(x.unsqueeze(0), size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        return x, torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "def build_bleaching_classification(size: int = 128):\n",
    "    pairs = CoralBleachingPairs(BLEACH_IMAGES, BLEACH_COMBINED, BLEACH_SINGLE)\n",
    "    return PairToImages128WithLabels(pairs, size)\n",
    "\n",
    "# ---------------- Benthic (your SegmentationDataset -> (img, mask) tensors) → classification ----------------\n",
    "# We’ll collect whichever of your wrapped datasets exist in the namespace.\n",
    "def collect_benthic_wrapped():\n",
    "    names = [\n",
    "        \"BOLIVAR_t\",\"COURTOWN_t\",\"PAC_USA_t\",\"IDN_PHL_t\",\"PAC_AUS_t\",\"TETES_t\",\"ATL_t\",\"TAYRONA_t\"\n",
    "    ]\n",
    "    found = []\n",
    "    for n in names:\n",
    "        if n in globals():\n",
    "            found.append(globals()[n])\n",
    "    print(f\"[benthic] using {len(found)} wrapped datasets: {[n for n in names if n in globals()]}\")\n",
    "    return found\n",
    "\n",
    "class BenthicToImages128WithLabels(Dataset):\n",
    "    def __init__(self, base_ds: Dataset, size=128, min_ratio=1.05, min_signal=0.01):\n",
    "        self.base = base_ds\n",
    "        self.size = size\n",
    "        self.keep_idx = []\n",
    "        self.labels = []\n",
    "        # pre-scan to keep only confidently labeled samples\n",
    "        for i in range(len(self.base)):\n",
    "            img, mask = self.base[i]  # tensors (3,H,W)\n",
    "            y = label_from_mask_tensor(mask, min_ratio=min_ratio, min_signal=min_signal)\n",
    "            if y is not None:\n",
    "                self.keep_idx.append(i)\n",
    "                self.labels.append(int(y))\n",
    "        print(f\"[benthic filter] kept {len(self.keep_idx)}/{len(self.base)} (min_ratio={min_ratio}, min_signal={min_signal})\")\n",
    "\n",
    "    def __len__(self): return len(self.keep_idx)\n",
    "    def __getitem__(self, j):\n",
    "        i = self.keep_idx[j]\n",
    "        img, mask = self.base[i]\n",
    "        # resize image to 128\n",
    "        if img.shape[-2:] != (self.size, self.size):\n",
    "            img = F.interpolate(img.unsqueeze(0), size=(self.size,self.size), mode=\"bilinear\", align_corners=False).squeeze(0)\n",
    "        return img, torch.tensor(self.labels[j], dtype=torch.long)\n",
    "\n",
    "def build_benthic_classification(size: int = 128):\n",
    "    ds_list = collect_benthic_wrapped()\n",
    "    out = []\n",
    "    for ds in ds_list:\n",
    "        out.append(BenthicToImages128WithLabels(ds, size=size, min_ratio=1.05, min_signal=0.01))\n",
    "    if not out:\n",
    "        return None, None\n",
    "    # Concat all benthic; split 85/15\n",
    "    benthic_all = ConcatDataset(out)\n",
    "    n = len(benthic_all)\n",
    "    n_val = max(1, int(0.15*n))\n",
    "    idx = torch.randperm(n).tolist()\n",
    "    val_ids = set(idx[:n_val])\n",
    "    benthic_val = Subset(benthic_all, list(val_ids))\n",
    "    benthic_train = Subset(benthic_all, [i for i in range(n) if i not in val_ids])\n",
    "    return benthic_train, benthic_val\n",
    "\n",
    "# ---------------- Build datasets & combine ----------------\n",
    "cs_train, cs_val = build_coralscapes_classification(size=128)\n",
    "bl_all = build_bleaching_classification(size=128)\n",
    "# split bleaching 85/15\n",
    "n_bl = len(bl_all); n_bl_val = max(1, int(0.15*n_bl))\n",
    "perm = torch.randperm(n_bl).tolist()\n",
    "bl_val = Subset(bl_all, perm[:n_bl_val])\n",
    "bl_train = Subset(bl_all, perm[n_bl_val:])\n",
    "\n",
    "bt_train, bt_val = build_benthic_classification(size=128)\n",
    "\n",
    "# combine available pieces\n",
    "train_parts = [cs_train, bl_train] + ([bt_train] if bt_train is not None else [])\n",
    "val_parts   = [cs_val,   bl_val]   + ([bt_val]   if bt_val   is not None else [])\n",
    "train_cls = ConcatDataset(train_parts)\n",
    "val_cls   = ConcatDataset(val_parts)\n",
    "\n",
    "print(f\"[combined] train={len(train_cls)} | val={len(val_cls)}\")\n",
    "\n",
    "# ---------------- Balanced training: Class-Balanced Focal Loss (no sampler) ----------------\n",
    "def get_label_counts(ds: Dataset):\n",
    "    n0=n1=0\n",
    "    for i in range(len(ds)):\n",
    "        y = ds[i][1]\n",
    "        y = int(y) if isinstance(y, torch.Tensor) else int(y)\n",
    "        if y==0: n0+=1\n",
    "        else: n1+=1\n",
    "    return n0, n1\n",
    "\n",
    "n0, n1 = get_label_counts(train_cls)\n",
    "print(f\"[labels] train counts → healthy(0)={n0} | unhealthy(1)={n1}\")\n",
    "\n",
    "def class_balanced_weights(n_per_class, beta=0.99):\n",
    "    w=[]\n",
    "    for n in n_per_class:\n",
    "        n=max(1,n); w_c=(1-beta)/(1-beta**n); w.append(w_c)\n",
    "    m=sum(w)/len(w)\n",
    "    return torch.tensor([wc/m for wc in w], dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "cb_alpha = class_balanced_weights([n0, n1], beta=0.99)\n",
    "print(\"[CB weights] alpha:\", cb_alpha.tolist())\n",
    "\n",
    "def focal_ce_loss(logits, target, alpha=None, gamma=1.0):\n",
    "    ce = F.cross_entropy(logits, target, reduction=\"none\")\n",
    "    pt = F.softmax(logits, dim=1).gather(1, target.view(-1,1)).squeeze(1).clamp_(1e-6, 1-1e-6)\n",
    "    loss = ce * ((1 - pt) ** gamma)\n",
    "    if alpha is not None:\n",
    "        loss = loss * alpha[target]\n",
    "    return loss.mean()\n",
    "\n",
    "BATCH = 8  # 16/8 if VRAM is tight\n",
    "train_loader = DataLoader(train_cls, batch_size=BATCH, shuffle=True,  num_workers=0, pin_memory=True)\n",
    "val_loader   = DataLoader(val_cls,   batch_size=BATCH, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "# ---------------- Keras-like CNN (conv stack + GAP head) ----------------\n",
    "class KerasLikeCNN_GAP(nn.Module):\n",
    "    def __init__(self, p_drop=0.3):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=0), nn.ReLU(True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=0), nn.ReLU(True),\n",
    "            nn.Conv2d(64, 32, 1), nn.ReLU(True),\n",
    "            nn.Conv2d(32, 64, 1), nn.ReLU(True),\n",
    "            nn.Conv2d(64,128, 3, padding=0), nn.ReLU(True),\n",
    "            nn.Dropout(p_drop),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        self.head = nn.Linear(128, 2)\n",
    "    def forward(self, x):\n",
    "        return self.head(self.features(x).flatten(1))\n",
    "\n",
    "model = KerasLikeCNN_GAP().to(DEVICE)\n",
    "\n",
    "# bias warm-start to prior\n",
    "N = n0+n1\n",
    "p1 = (n1 + 1e-6) / (N + 2e-6)\n",
    "prior_logit = math.log(p1/(1-p1))\n",
    "with torch.no_grad():\n",
    "    model.head.bias[:] = torch.tensor([-prior_logit, prior_logit], device=DEVICE, dtype=model.head.bias.dtype)\n",
    "\n",
    "opt = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "scaler = GradScaler(enabled=(DEVICE.type==\"cuda\"))\n",
    "criterion = lambda logits, y: focal_ce_loss(logits, y, alpha=cb_alpha, gamma=1.0)\n",
    "\n",
    "# ---------------- Train with early stopping ----------------\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=6, min_delta=1e-3):\n",
    "        self.patience=patience; self.min_delta=min_delta\n",
    "        self.best=float(\"inf\"); self.count=0\n",
    "    def step(self, v):\n",
    "        if self.best - v > self.min_delta:\n",
    "            self.best=v; self.count=0; return False\n",
    "        self.count+=1; return self.count>=self.patience\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train() if train else model.eval()\n",
    "    loss_sum=correct=n=0\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(DEVICE, non_blocking=True), yb.to(DEVICE, non_blocking=True)\n",
    "        if train: opt.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train), autocast(\"cuda\", enabled=(DEVICE.type==\"cuda\")):\n",
    "            logits = model(xb)\n",
    "            loss = criterion(logits, yb)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
    "        loss_sum += loss.item()*xb.size(0)\n",
    "        correct  += (logits.argmax(1)==yb).sum().item()\n",
    "        n += xb.size(0)\n",
    "    return loss_sum/max(1,n), correct/max(1,n)\n",
    "\n",
    "EPOCHS = 2\n",
    "early = EarlyStopper(patience=6, min_delta=1e-3)\n",
    "best_state=None\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    t0=time.time()\n",
    "    tr_loss,tr_acc = run_epoch(train_loader, True)\n",
    "    va_loss,va_acc = run_epoch(val_loader,   False)\n",
    "    print(f\"Epoch {ep:02d}/{EPOCHS} - loss:{tr_loss:.4f} - acc:{tr_acc:.4f} - val_loss:{va_loss:.4f} - val_acc:{va_acc:.4f} - {time.time()-t0:.1f}s\")\n",
    "    if best_state is None or va_loss < (early.best-1e-3):\n",
    "        best_state = {k:v.detach().cpu().clone() for k,v in model.state_dict().items()}\n",
    "    if early.step(va_loss):\n",
    "        print(f\"Epoch {ep}: early stopping (best val_loss={early.best:.4f})\")\n",
    "        break\n",
    "if best_state:\n",
    "    model.load_state_dict(best_state)\n",
    "    print(\"Loaded best weights.\")\n",
    "\n",
    "# ---------------- Threshold tuning (maximize macro-F1) ----------------\n",
    "@torch.no_grad()\n",
    "def collect_val_probs_and_labels(model, loader):\n",
    "    model.eval()\n",
    "    probs=[]; labels=[]\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(DEVICE)\n",
    "        with autocast(\"cuda\", enabled=(DEVICE.type==\"cuda\")):\n",
    "            p1 = F.softmax(model(xb), dim=1)[:,1]\n",
    "        probs.append(p1.cpu()); labels.append(yb.cpu())\n",
    "    return torch.cat(probs), torch.cat(labels)\n",
    "\n",
    "def metrics_from_preds(y_true, y_pred):\n",
    "    cm = torch.zeros(2,2, dtype=torch.int64)\n",
    "    for t,p in zip(y_true, y_pred): cm[t,p]+=1\n",
    "    def prf(c):\n",
    "        tp=cm[c,c].item(); fp=cm[:,c].sum().item()-tp; fn=cm[c,:].sum().item()-tp\n",
    "        prec = tp / max(1,tp+fp); rec = tp / max(1,tp+fn)\n",
    "        f1 = 0.0 if prec+rec==0 else 2*prec*rec/(prec+rec)\n",
    "        return prec, rec, f1\n",
    "    p0,r0,f0 = prf(0); p1,r1,f1 = prf(1)\n",
    "    macro = 0.5*(f0+f1)\n",
    "    acc = (y_true==y_pred).float().mean().item()\n",
    "    return {\"acc\":acc,\"macro_f1\":macro,\"cm\":cm,\"per\":{\"healthy\":(p0,r0,f0),\"unhealthy\":(p1,r1,f1)}}\n",
    "\n",
    "probs, y_true = collect_val_probs_and_labels(model, val_loader)\n",
    "best = {\"t\":0.5,\"macro_f1\":-1}\n",
    "for t in torch.linspace(0.1, 0.9, steps=17):\n",
    "    y_pred = (probs >= t).long()\n",
    "    m = metrics_from_preds(y_true, y_pred)\n",
    "    if m[\"macro_f1\"] > best[\"macro_f1\"]:\n",
    "        best = {\"t\": float(t), \"macro_f1\": m[\"macro_f1\"], \"metrics\": m}\n",
    "\n",
    "m = best[\"metrics\"]; cm = m[\"cm\"].numpy()\n",
    "(p0,r0,f0) = m[\"per\"][\"healthy\"]; (p1_,r1_,f1_) = m[\"per\"][\"unhealthy\"]\n",
    "print(f\"\\nBest threshold t={best['t']:.2f} (macro-F1={best['macro_f1']:.3f})\")\n",
    "print(f\"Overall: acc={m['acc']:.3f} | macro-F1={m['macro_f1']:.3f}\")\n",
    "print(\"Confusion Matrix (rows=true, cols=pred):\")\n",
    "print(f\"            pred: healthy   pred: unhealthy\")\n",
    "print(f\"true healthy     {cm[0,0]:>6}          {cm[0,1]:>6}\")\n",
    "print(f\"true unhealthy   {cm[1,0]:>6}          {cm[1,1]:>6}\")\n",
    "print(f\"healthy   | precision={p0:.3f} | recall={r0:.3f} | f1={f0:.3f}\")\n",
    "print(f\"unhealthy | precision={p1_:.3f} | recall={r1_:.3f} | f1={f1_:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modern_ts_2E",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
